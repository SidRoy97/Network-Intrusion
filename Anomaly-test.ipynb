{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "82332/82332 [==============================] - 7s 83us/step\n",
      "\n",
      "Loss: 0.50, Accuracy: 73.24%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.732401\n",
      "racall\n",
      "0.965675\n",
      "precision\n",
      "0.681317\n",
      "f1score\n",
      "0.798949\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/dnn1/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "#model.load_weights(\"results/dnn1/checkpoint-01.hdf5\")\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expecteddnn1.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicteddnn1.txt', y_pred, fmt='%01d')\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"dnn1.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "82332/82332 [==============================] - 13s 155us/step\n",
      "\n",
      "Loss: 0.50, Accuracy: 73.24%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.732376\n",
      "racall\n",
      "0.977433\n",
      "precision\n",
      "0.678337\n",
      "f1score\n",
      "0.800871\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/dnn2/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expecteddnn2.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicteddnn2.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"dnn2.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 14s 168us/step\n",
      "\n",
      "Loss: 0.50, Accuracy: 73.38%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.733834\n",
      "racall\n",
      "0.983080\n",
      "precision\n",
      "0.678187\n",
      "f1score\n",
      "0.802655\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/dnn3/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expecteddnn3.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicteddnn3.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"dnn3.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 18s 223us/step\n",
      "\n",
      "Loss: 0.50, Accuracy: 72.50%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.725028\n",
      "racall\n",
      "0.988441\n",
      "precision\n",
      "0.669546\n",
      "f1score\n",
      "0.798325\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/dnn4/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expecteddnn4.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicteddnn4.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"dnn4.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 18s 214us/step\n",
      "\n",
      "Loss: 0.50, Accuracy: 73.23%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.732255\n",
      "racall\n",
      "0.986389\n",
      "precision\n",
      "0.676045\n",
      "f1score\n",
      "0.802250\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/dnn5/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expecteddnn5.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicteddnn5.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"dnn5.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 4s 53us/step\n",
      "\n",
      "Loss: 0.49, Accuracy: 72.49%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.724894\n",
      "racall\n",
      "0.892350\n",
      "precision\n",
      "0.694789\n",
      "f1score\n",
      "0.781274\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/gru/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedgru.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedgru.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"gru.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(8, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 6s 74us/step\n",
      "\n",
      "Loss: 0.49, Accuracy: 71.96%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.719587\n",
      "racall\n",
      "0.964418\n",
      "precision\n",
      "0.670609\n",
      "f1score\n",
      "0.791115\n",
      "==============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom sklearn.metrics import confusion_matrix\\nimport os\\nfor file in os.listdir(\"kddresults/lstm2layer/\"):\\n  model.load_weights(\"kddresults/lstm2layer/\"+file)\\n  model.compile(loss=\\'binary_crossentropy\\',optimizer=\\'adam\\',metrics=[\\'accuracy\\'])\\n  y_train1 = y_test\\n  y_pred = model.predict_classes(X_train)\\n  accuracy = accuracy_score(y_train1, y_pred)\\n  recall = recall_score(y_train1, y_pred , average=\"binary\")\\n  precision = precision_score(y_train1, y_pred , average=\"binary\")\\n  f1 = f1_score(y_train1, y_pred, average=\"binary\")\\n  print(\"confusion matrix\")\\n  print(\"----------------------------------------------\")\\n  print(\"accuracy\")\\n  print(\"%.3f\" %accuracy)\\n  print(\"racall\")\\n  print(\"%.3f\" %recall)\\n  print(\"precision\")\\n  print(\"%.3f\" %precision)\\n  print(\"f1score\")\\n  print(\"%.3f\" %f1)\\n  #cm = metrics.confusion_matrix(y_train1, y_pred)\\n  print(\"==============================================\")\\n\\n\\nprint(cm)\\ntp = cm[0][0]\\nfp = cm[0][1]\\ntn = cm[1][1]\\nfn = cm[1][0]\\nprint(\"tp\")\\nprint(tp)\\nprint(\"fp\")\\nprint(fp)\\nprint(\"tn\")\\nprint(tn)\\nprint(\"fn\")\\nprint(fn)\\n\\nprint(\"tpr\")\\ntpr = float(tp)/(tp+fn)\\nprint(\"fpr\")\\nfpr = float(fp)/(fp+tn)\\nprint(\"LSTM acc\")\\nprint(tpr)\\nprint(fpr)\\n\\n\\nmodel.compile(loss=\\'binary_crossentropy\\',optimizer=\\'adam\\',metrics=[\\'accuracy\\'])\\nloss, accuracy = model.evaluate(X_train, y_train1)\\nprint(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\\n\\n\\n\\n\\n\\n\\n# try using different optimizers and different optimizer configs\\nmodel.compile(loss=\\'binary_crossentropy\\',optimizer=\\'adam\\',metrics=[\\'accuracy\\'])\\ncheckpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/lstm2layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor=\\'val_acc\\',mode=\\'max\\')\\ncsv_logger = CSVLogger(\\'training_set_iranalysis1.csv\\',separator=\\',\\', append=False)\\nmodel.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1000, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\\nmodel.save(\"kddresults/lstm2layer/fullmodel/lstm2layer_model.hdf5\")\\n\\nloss, accuracy = model.evaluate(X_test, y_test)\\nprint(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\\ny_pred = model.predict_classes(X_test)\\nnp.savetxt(\\'kddresults/lstm2layer/lstm2predicted.txt\\', np.transpose([y_test,y_pred]), fmt=\\'%01d\\')\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/gru1/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedgru1.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedgru1.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"gru1.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "for file in os.listdir(\"kddresults/lstm2layer/\"):\n",
    "  model.load_weights(\"kddresults/lstm2layer/\"+file)\n",
    "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "  y_train1 = y_test\n",
    "  y_pred = model.predict_classes(X_train)\n",
    "  accuracy = accuracy_score(y_train1, y_pred)\n",
    "  recall = recall_score(y_train1, y_pred , average=\"binary\")\n",
    "  precision = precision_score(y_train1, y_pred , average=\"binary\")\n",
    "  f1 = f1_score(y_train1, y_pred, average=\"binary\")\n",
    "  print(\"confusion matrix\")\n",
    "  print(\"----------------------------------------------\")\n",
    "  print(\"accuracy\")\n",
    "  print(\"%.3f\" %accuracy)\n",
    "  print(\"racall\")\n",
    "  print(\"%.3f\" %recall)\n",
    "  print(\"precision\")\n",
    "  print(\"%.3f\" %precision)\n",
    "  print(\"f1score\")\n",
    "  print(\"%.3f\" %f1)\n",
    "  #cm = metrics.confusion_matrix(y_train1, y_pred)\n",
    "  print(\"==============================================\")\n",
    "\n",
    "\n",
    "print(cm)\n",
    "tp = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "tn = cm[1][1]\n",
    "fn = cm[1][0]\n",
    "print(\"tp\")\n",
    "print(tp)\n",
    "print(\"fp\")\n",
    "print(fp)\n",
    "print(\"tn\")\n",
    "print(tn)\n",
    "print(\"fn\")\n",
    "print(fn)\n",
    "\n",
    "print(\"tpr\")\n",
    "tpr = float(tp)/(tp+fn)\n",
    "print(\"fpr\")\n",
    "fpr = float(fp)/(fp+tn)\n",
    "print(\"LSTM acc\")\n",
    "print(tpr)\n",
    "print(fpr)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_train, y_train1)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/lstm2layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1000, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"kddresults/lstm2layer/fullmodel/lstm2layer_model.hdf5\")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "np.savetxt('kddresults/lstm2layer/lstm2predicted.txt', np.transpose([y_test,y_pred]), fmt='%01d')\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(16, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 7s 81us/step\n",
      "\n",
      "Loss: 0.50, Accuracy: 72.32%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.723206\n",
      "racall\n",
      "0.981558\n",
      "precision\n",
      "0.669626\n",
      "f1score\n",
      "0.796128\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/gru2/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedgru2.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedgru2.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"gru2.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(32, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 11s 128us/step\n",
      "\n",
      "Loss: 0.52, Accuracy: 72.80%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.727992\n",
      "racall\n",
      "0.985330\n",
      "precision\n",
      "0.672726\n",
      "f1score\n",
      "0.799560\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/gru3/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedgru3.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedgru3.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"gru3.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 3s 34us/step\n",
      "\n",
      "Loss: 0.51, Accuracy: 71.09%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.710878\n",
      "racall\n",
      "0.829988\n",
      "precision\n",
      "0.700365\n",
      "f1score\n",
      "0.759687\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/lstm/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedlstm.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedlstm.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"lstm.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(8, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 4s 45us/step\n",
      "\n",
      "Loss: 0.49, Accuracy: 72.51%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.725089\n",
      "racall\n",
      "0.898085\n",
      "precision\n",
      "0.693253\n",
      "f1score\n",
      "0.782487\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/lstm1/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedlstm1.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedlstm1.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"lstm1.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(16, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 5s 60us/step\n",
      "\n",
      "Loss: 0.51, Accuracy: 70.74%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.707416\n",
      "racall\n",
      "0.992456\n",
      "precision\n",
      "0.654524\n",
      "f1score\n",
      "0.788821\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/lstm2/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedlstm2.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedlstm2.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"lstm2.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(32, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 5s 66us/step\n",
      "\n",
      "Loss: 0.50, Accuracy: 71.37%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.713671\n",
      "racall\n",
      "0.987007\n",
      "precision\n",
      "0.660628\n",
      "f1score\n",
      "0.791491\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/lstm3/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedlstm3.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedlstm3.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"lstm3.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "82332/82332 [==============================] - 5s 58us/step\n",
      "\n",
      "Loss: 0.52, Accuracy: 72.89%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.728939\n",
      "racall\n",
      "0.806649\n",
      "precision\n",
      "0.729604\n",
      "f1score\n",
      "0.766194\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/rnn/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedrnn.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedrnn.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"rnn.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(8, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 6s 70us/step\n",
      "\n",
      "Loss: 0.49, Accuracy: 71.22%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.712190\n",
      "racall\n",
      "0.978624\n",
      "precision\n",
      "0.661246\n",
      "f1score\n",
      "0.789223\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/rnn1/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedrnn1.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedrnn1.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"rnn1.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(16, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 7s 89us/step\n",
      "\n",
      "Loss: 0.53, Accuracy: 70.97%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.709663\n",
      "racall\n",
      "0.981205\n",
      "precision\n",
      "0.658651\n",
      "f1score\n",
      "0.788205\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/rnn2/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedrnn2.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedrnn2.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"rnn2.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(32, return_sequences=True, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 9s 103us/step\n",
      "\n",
      "Loss: 0.51, Accuracy: 70.59%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.705874\n",
      "racall\n",
      "0.986169\n",
      "precision\n",
      "0.654596\n",
      "f1score\n",
      "0.786880\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/rnn3/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "model.load_weights(latest_file)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('res/expectedrnn3.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predictedrnn3.txt', y_pred, fmt='%01d')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "np.savetxt(\"rnn3.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 13s 155us/step\n",
      "\n",
      "Loss: 0.48, Accuracy: 74.36%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.743611\n",
      "racall\n",
      "0.972029\n",
      "precision\n",
      "0.689524\n",
      "f1score\n",
      "0.806760\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import GRU, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "\n",
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "'''\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru1results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru1results/cnntrainanalysis1.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=1000, show_accuracy=True,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru1results/cnn_model.hdf5\")\n",
    "'''\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/cnn-gru1results/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "cnn.load_weights(latest_file)\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "y_pred = cnn.predict_classes(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "np.savetxt('res/expected-cnn-gru-1.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicted-cnn-gru-1.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 16s 194us/step\n",
      "\n",
      "Loss: 0.39, Accuracy: 75.54%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.755417\n",
      "racall\n",
      "0.976463\n",
      "precision\n",
      "0.698903\n",
      "f1score\n",
      "0.814691\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import GRU, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "'''\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru2results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru2results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=1000, show_accuracy=True,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru2results/cnn_model.hdf5\")\n",
    "'''\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/cnn-gru2results/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "cnn.load_weights(latest_file)\n",
    "\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "y_pred = cnn.predict_classes(X_test)\n",
    "np.savetxt(\"cnngru.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "np.savetxt('res/expected-cnn-gru-2.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicted-cnn-gru-2.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:76: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82332/82332 [==============================] - 19s 235us/step\n",
      "\n",
      "Loss: 0.38, Accuracy: 76.41%\n",
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.764089\n",
      "racall\n",
      "0.965675\n",
      "precision\n",
      "0.710154\n",
      "f1score\n",
      "0.818434\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import GRU, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_testing_set.csv',skiprows=1,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "'''\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru3results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru3results/cnntrainanalysis3.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=1000, show_accuracy=True,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru3results/cnn_model.hdf5\")\n",
    "'''\n",
    "\n",
    "\n",
    "list_of_files = glob.glob('C:/Users/roysi/Documents/programs/network-security-new/results/cnn-gru3results/*.hdf5')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "cnn.load_weights(latest_file)\n",
    "\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "y_pred = cnn.predict_classes(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "np.savetxt('res/expected-cnn-gru-3.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicted-cnn-gru-3.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
