{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 1,
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:83: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
=======
      "Using TensorFlow backend.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 9s 63us/step - loss: 0.4624 - acc: 0.7304 - val_loss: 0.1722 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.46240, saving model to results/dnn1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 9s 64us/step - loss: 0.4407 - acc: 0.7605 - val_loss: 0.1258 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00002: loss improved from 0.46240 to 0.44067, saving model to results/dnn1/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 8s 59us/step - loss: 0.4231 - acc: 0.7878 - val_loss: 0.1250 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00003: loss improved from 0.44067 to 0.42311, saving model to results/dnn1/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 9s 64us/step - loss: 0.4074 - acc: 0.8057 - val_loss: 0.1627 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00004: loss improved from 0.42311 to 0.40738, saving model to results/dnn1/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 9s 61us/step - loss: 0.3942 - acc: 0.8157 - val_loss: 0.1499 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00005: loss improved from 0.40738 to 0.39420, saving model to results/dnn1/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 9s 63us/step - loss: 0.3848 - acc: 0.8219 - val_loss: 0.1274 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00006: loss improved from 0.39420 to 0.38479, saving model to results/dnn1/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3777 - acc: 0.8254 - val_loss: 0.1421 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00007: loss improved from 0.38479 to 0.37774, saving model to results/dnn1/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3729 - acc: 0.8267 - val_loss: 0.1480 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00008: loss improved from 0.37774 to 0.37288, saving model to results/dnn1/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 8s 59us/step - loss: 0.3685 - acc: 0.8300 - val_loss: 0.1348 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00009: loss improved from 0.37288 to 0.36849, saving model to results/dnn1/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3663 - acc: 0.8314 - val_loss: 0.1463 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00010: loss improved from 0.36849 to 0.36627, saving model to results/dnn1/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3633 - acc: 0.8331 - val_loss: 0.1068 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00011: loss improved from 0.36627 to 0.36332, saving model to results/dnn1/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 9s 64us/step - loss: 0.3614 - acc: 0.8342 - val_loss: 0.1461 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00012: loss improved from 0.36332 to 0.36139, saving model to results/dnn1/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.3604 - acc: 0.8347 - val_loss: 0.0910 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00013: loss improved from 0.36139 to 0.36043, saving model to results/dnn1/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 9s 67us/step - loss: 0.3591 - acc: 0.8355 - val_loss: 0.1362 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00014: loss improved from 0.36043 to 0.35910, saving model to results/dnn1/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 9s 65us/step - loss: 0.3582 - acc: 0.8359 - val_loss: 0.1233 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00015: loss improved from 0.35910 to 0.35823, saving model to results/dnn1/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 9s 63us/step - loss: 0.3583 - acc: 0.8356 - val_loss: 0.1154 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.35823\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3566 - acc: 0.8370 - val_loss: 0.1297 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00017: loss improved from 0.35823 to 0.35664, saving model to results/dnn1/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 8s 57us/step - loss: 0.3565 - acc: 0.8367 - val_loss: 0.1115 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00018: loss improved from 0.35664 to 0.35647, saving model to results/dnn1/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 8s 59us/step - loss: 0.3565 - acc: 0.8365 - val_loss: 0.0995 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.35647\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 8s 55us/step - loss: 0.3553 - acc: 0.8374 - val_loss: 0.1190 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00020: loss improved from 0.35647 to 0.35527, saving model to results/dnn1/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 8s 59us/step - loss: 0.3546 - acc: 0.8386 - val_loss: 0.0876 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00021: loss improved from 0.35527 to 0.35464, saving model to results/dnn1/checkpoint-21.hdf5\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.3553 - acc: 0.8379 - val_loss: 0.0942 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.35464\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3554 - acc: 0.8375 - val_loss: 0.1108 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.35464\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 9s 62us/step - loss: 0.3553 - acc: 0.8384 - val_loss: 0.2004 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.35464\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 8s 58us/step - loss: 0.3546 - acc: 0.8376 - val_loss: 0.1535 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00025: loss improved from 0.35464 to 0.35463, saving model to results/dnn1/checkpoint-25.hdf5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn1/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn1/dnn1layer_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 68s 488us/step - loss: 0.4344 - acc: 0.7665 - val_loss: 0.1423 - val_acc: 0.9657\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.43442, saving model to results/dnn2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 64s 456us/step - loss: 0.3956 - acc: 0.8064 - val_loss: 0.1255 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00002: loss improved from 0.43442 to 0.39559, saving model to results/dnn2/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 65s 466us/step - loss: 0.3758 - acc: 0.8226 - val_loss: 0.1077 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00003: loss improved from 0.39559 to 0.37576, saving model to results/dnn2/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 64s 456us/step - loss: 0.3613 - acc: 0.8314 - val_loss: 0.1647 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00004: loss improved from 0.37576 to 0.36135, saving model to results/dnn2/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 64s 457us/step - loss: 0.3551 - acc: 0.8357 - val_loss: 0.1493 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00005: loss improved from 0.36135 to 0.35506, saving model to results/dnn2/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 64s 456us/step - loss: 0.3529 - acc: 0.8370 - val_loss: 0.1490 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00006: loss improved from 0.35506 to 0.35294, saving model to results/dnn2/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 65s 463us/step - loss: 0.3524 - acc: 0.8374 - val_loss: 0.1462 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00007: loss improved from 0.35294 to 0.35236, saving model to results/dnn2/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 72s 512us/step - loss: 0.3500 - acc: 0.8392 - val_loss: 0.1379 - val_acc: 0.9902 ETA: 4s - loss: 0.3508 - ac - ETA: 4s - ETA: 0s - loss: 0.3501 - acc: 0.83\n",
      "\n",
      "Epoch 00008: loss improved from 0.35236 to 0.35003, saving model to results/dnn2/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 71s 508us/step - loss: 0.3496 - acc: 0.8400 - val_loss: 0.1286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00009: loss improved from 0.35003 to 0.34957, saving model to results/dnn2/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 68s 487us/step - loss: 0.3482 - acc: 0.8413 - val_loss: 0.1399 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00010: loss improved from 0.34957 to 0.34821, saving model to results/dnn2/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 69s 493us/step - loss: 0.3479 - acc: 0.8413 - val_loss: 0.1208 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00011: loss improved from 0.34821 to 0.34785, saving model to results/dnn2/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 64s 457us/step - loss: 0.3466 - acc: 0.8421 - val_loss: 0.1526 - val_acc: 0.9575\n",
      "\n",
      "Epoch 00012: loss improved from 0.34785 to 0.34663, saving model to results/dnn2/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 66s 470us/step - loss: 0.3495 - acc: 0.8425 - val_loss: 0.1188 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.34663\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 69s 493us/step - loss: 0.3471 - acc: 0.8416 - val_loss: 0.1288 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.34663\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 69s 495us/step - loss: 0.3459 - acc: 0.8425 - val_loss: 0.1115 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00015: loss improved from 0.34663 to 0.34587, saving model to results/dnn2/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 71s 506us/step - loss: 0.3470 - acc: 0.8420 - val_loss: 0.1315 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.34587\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 74s 529us/step - loss: 0.3448 - acc: 0.8436 - val_loss: 0.1262 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00017: loss improved from 0.34587 to 0.34478, saving model to results/dnn2/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 69s 489us/step - loss: 0.3456 - acc: 0.8432 - val_loss: 0.1007 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.34478\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 69s 492us/step - loss: 0.3459 - acc: 0.8424 - val_loss: 0.1192 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.34478\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 71s 504us/step - loss: 0.3453 - acc: 0.8432 - val_loss: 0.1171 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.34478\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 66s 473us/step - loss: 0.3435 - acc: 0.8443 - val_loss: 0.1259 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00021: loss improved from 0.34478 to 0.34348, saving model to results/dnn2/checkpoint-21.hdf5\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 67s 477us/step - loss: 0.3432 - acc: 0.8451 - val_loss: 0.1460 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00022: loss improved from 0.34348 to 0.34319, saving model to results/dnn2/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 65s 466us/step - loss: 0.3441 - acc: 0.8444 - val_loss: 0.1316 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.34319\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 64s 459us/step - loss: 0.3440 - acc: 0.8442 - val_loss: 0.1187 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.34319\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 65s 465us/step - loss: 0.3438 - acc: 0.8443 - val_loss: 0.1469 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.34319\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn2/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn2/dnn2_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 97s 689us/step - loss: 0.4236 - acc: 0.7780 - val_loss: 0.1730 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.42356, saving model to results/dnn3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 95s 676us/step - loss: 0.3966 - acc: 0.8009 - val_loss: 0.1603 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00002: loss improved from 0.42356 to 0.39661, saving model to results/dnn3/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 100s 715us/step - loss: 0.3887 - acc: 0.8092 - val_loss: 0.1304 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00003: loss improved from 0.39661 to 0.38868, saving model to results/dnn3/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 98s 702us/step - loss: 0.3672 - acc: 0.8275 - val_loss: 0.1255 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00004: loss improved from 0.38868 to 0.36719, saving model to results/dnn3/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 95s 680us/step - loss: 0.3568 - acc: 0.8347 - val_loss: 0.1428 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00005: loss improved from 0.36719 to 0.35681, saving model to results/dnn3/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 99s 703us/step - loss: 0.3534 - acc: 0.8369 - val_loss: 0.1438 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00006: loss improved from 0.35681 to 0.35338, saving model to results/dnn3/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 95s 674us/step - loss: 0.3520 - acc: 0.8380 - val_loss: 0.1256 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00007: loss improved from 0.35338 to 0.35196, saving model to results/dnn3/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 102s 730us/step - loss: 0.3487 - acc: 0.8407 - val_loss: 0.1169 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00008: loss improved from 0.35196 to 0.34872, saving model to results/dnn3/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 98s 696us/step - loss: 0.3487 - acc: 0.8401 - val_loss: 0.1338 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.34872\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 96s 681us/step - loss: 0.3493 - acc: 0.8404 - val_loss: 0.1433 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.34872\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 95s 676us/step - loss: 0.3484 - acc: 0.8411 - val_loss: 0.1137 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00011: loss improved from 0.34872 to 0.34840, saving model to results/dnn3/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 97s 690us/step - loss: 0.3471 - acc: 0.8410 - val_loss: 0.1199 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00012: loss improved from 0.34840 to 0.34708, saving model to results/dnn3/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 97s 690us/step - loss: 0.3479 - acc: 0.8408 - val_loss: 0.1212 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.34708\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 98s 695us/step - loss: 0.3470 - acc: 0.8415 - val_loss: 0.1362 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00014: loss improved from 0.34708 to 0.34701, saving model to results/dnn3/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 96s 683us/step - loss: 0.3467 - acc: 0.8418 - val_loss: 0.1338 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00015: loss improved from 0.34701 to 0.34668, saving model to results/dnn3/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 94s 671us/step - loss: 0.3461 - acc: 0.8418 - val_loss: 0.1404 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00016: loss improved from 0.34668 to 0.34611, saving model to results/dnn3/checkpoint-16.hdf5\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 95s 679us/step - loss: 0.3459 - acc: 0.8424 - val_loss: 0.1320 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00017: loss improved from 0.34611 to 0.34589, saving model to results/dnn3/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 98s 696us/step - loss: 0.3459 - acc: 0.8427 - val_loss: 0.1188 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00018: loss improved from 0.34589 to 0.34588, saving model to results/dnn3/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 104s 740us/step - loss: 0.3446 - acc: 0.8436 - val_loss: 0.1230 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00019: loss improved from 0.34588 to 0.34462, saving model to results/dnn3/checkpoint-19.hdf5\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 96s 688us/step - loss: 0.3439 - acc: 0.8446 - val_loss: 0.1220 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00020: loss improved from 0.34462 to 0.34388, saving model to results/dnn3/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 98s 700us/step - loss: 0.3445 - acc: 0.8439 - val_loss: 0.1161 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.34388\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 100s 711us/step - loss: 0.3430 - acc: 0.8453 - val_loss: 0.1327 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00022: loss improved from 0.34388 to 0.34298, saving model to results/dnn3/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 100s 710us/step - loss: 0.3436 - acc: 0.8447 - val_loss: 0.1067 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.34298\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 100s 712us/step - loss: 0.3433 - acc: 0.8443 - val_loss: 0.1334 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.34298\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 100s 716us/step - loss: 0.3444 - acc: 0.8433 - val_loss: 0.1211 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.34298\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn3/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn3/dnn3_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.4241 - acc: 0.7774 - val_loss: 0.1989 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.42407, saving model to results/dnn4/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 109s 779us/step - loss: 0.4000 - acc: 0.7995 - val_loss: 0.1924 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00002: loss improved from 0.42407 to 0.40004, saving model to results/dnn4/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 125s 891us/step - loss: 0.3963 - acc: 0.8020 - val_loss: 0.1355 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00003: loss improved from 0.40004 to 0.39632, saving model to results/dnn4/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 112s 796us/step - loss: 0.3880 - acc: 0.8119 - val_loss: 0.1230 - val_acc: 0.9802: 0.81 - ETA: 0s - loss: 0.3879 - acc: 0.811\n",
      "\n",
      "Epoch 00004: loss improved from 0.39632 to 0.38795, saving model to results/dnn4/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 106s 757us/step - loss: 0.3662 - acc: 0.8263 - val_loss: 0.1167 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00005: loss improved from 0.38795 to 0.36621, saving model to results/dnn4/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 99s 707us/step - loss: 0.3601 - acc: 0.8305 - val_loss: 0.1405 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00006: loss improved from 0.36621 to 0.36012, saving model to results/dnn4/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 100s 712us/step - loss: 0.3552 - acc: 0.8359 - val_loss: 0.1243 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00007: loss improved from 0.36012 to 0.35519, saving model to results/dnn4/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 100s 710us/step - loss: 0.3515 - acc: 0.8383 - val_loss: 0.1351 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00008: loss improved from 0.35519 to 0.35150, saving model to results/dnn4/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 97s 692us/step - loss: 0.3524 - acc: 0.8376 - val_loss: 0.1249 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.35150\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 99s 708us/step - loss: 0.3503 - acc: 0.8396 - val_loss: 0.1496 - val_acc: 0.99507s - lo - ETA: 2\n",
      "\n",
      "Epoch 00010: loss improved from 0.35150 to 0.35025, saving model to results/dnn4/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 97s 689us/step - loss: 0.3498 - acc: 0.8390 - val_loss: 0.1287 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00011: loss improved from 0.35025 to 0.34976, saving model to results/dnn4/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 99s 703us/step - loss: 0.3493 - acc: 0.8400 - val_loss: 0.1246 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00012: loss improved from 0.34976 to 0.34926, saving model to results/dnn4/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 99s 706us/step - loss: 0.3474 - acc: 0.8412 - val_loss: 0.1369 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00013: loss improved from 0.34926 to 0.34741, saving model to results/dnn4/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 100s 711us/step - loss: 0.3471 - acc: 0.8421 - val_loss: 0.1306 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00014: loss improved from 0.34741 to 0.34712, saving model to results/dnn4/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 101s 717us/step - loss: 0.3468 - acc: 0.8422 - val_loss: 0.1168 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00015: loss improved from 0.34712 to 0.34677, saving model to results/dnn4/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 102s 725us/step - loss: 0.3461 - acc: 0.8422 - val_loss: 0.1193 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00016: loss improved from 0.34677 to 0.34612, saving model to results/dnn4/checkpoint-16.hdf5\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 101s 717us/step - loss: 0.3453 - acc: 0.8425 - val_loss: 0.1281 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00017: loss improved from 0.34612 to 0.34529, saving model to results/dnn4/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 112s 798us/step - loss: 0.3463 - acc: 0.8421 - val_loss: 0.1259 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.34529\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 109s 779us/step - loss: 0.3463 - acc: 0.8423 - val_loss: 0.1185 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.34529\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 113s 809us/step - loss: 0.3451 - acc: 0.8427 - val_loss: 0.1262 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00020: loss improved from 0.34529 to 0.34512, saving model to results/dnn4/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 106s 755us/step - loss: 0.3452 - acc: 0.8436 - val_loss: 0.1357 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.34512\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 106s 755us/step - loss: 0.3450 - acc: 0.8435 - val_loss: 0.1463 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00022: loss improved from 0.34512 to 0.34503, saving model to results/dnn4/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 105s 746us/step - loss: 0.3443 - acc: 0.8437 - val_loss: 0.1107 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00023: loss improved from 0.34503 to 0.34432, saving model to results/dnn4/checkpoint-23.hdf5\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 101s 721us/step - loss: 0.3428 - acc: 0.8445 - val_loss: 0.1174 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00024: loss improved from 0.34432 to 0.34278, saving model to results/dnn4/checkpoint-24.hdf5\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 99s 706us/step - loss: 0.3435 - acc: 0.8438 - val_loss: 0.1363 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.34278\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn4/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn4/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn4/dnn4_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:76: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 105s 751us/step - loss: 0.4294 - acc: 0.7701 - val_loss: 0.1727 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.42945, saving model to results/dnn5/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 100s 711us/step - loss: 0.4065 - acc: 0.7954 - val_loss: 0.1211 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00002: loss improved from 0.42945 to 0.40646, saving model to results/dnn5/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 101s 720us/step - loss: 0.4022 - acc: 0.7982 - val_loss: 0.1340 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00003: loss improved from 0.40646 to 0.40221, saving model to results/dnn5/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 101s 720us/step - loss: 0.3964 - acc: 0.8022 - val_loss: 0.1620 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00004: loss improved from 0.40221 to 0.39639, saving model to results/dnn5/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 107s 760us/step - loss: 0.3951 - acc: 0.8064 - val_loss: 0.1292 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00005: loss improved from 0.39639 to 0.39512, saving model to results/dnn5/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 107s 763us/step - loss: 0.3699 - acc: 0.8236 - val_loss: 0.1295 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00006: loss improved from 0.39512 to 0.36990, saving model to results/dnn5/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 105s 746us/step - loss: 0.3630 - acc: 0.8288 - val_loss: 0.1073 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00007: loss improved from 0.36990 to 0.36299, saving model to results/dnn5/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 104s 743us/step - loss: 0.3581 - acc: 0.8340 - val_loss: 0.1396 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00008: loss improved from 0.36299 to 0.35806, saving model to results/dnn5/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 108s 767us/step - loss: 0.3570 - acc: 0.8340 - val_loss: 0.1183 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00009: loss improved from 0.35806 to 0.35698, saving model to results/dnn5/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 110s 783us/step - loss: 0.3526 - acc: 0.8379 - val_loss: 0.1388 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00010: loss improved from 0.35698 to 0.35255, saving model to results/dnn5/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 111s 793us/step - loss: 0.3546 - acc: 0.8366 - val_loss: 0.1186 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.35255\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 105s 747us/step - loss: 0.3516 - acc: 0.8384 - val_loss: 0.1045 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00012: loss improved from 0.35255 to 0.35162, saving model to results/dnn5/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 108s 773us/step - loss: 0.3512 - acc: 0.8390 - val_loss: 0.1175 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00013: loss improved from 0.35162 to 0.35121, saving model to results/dnn5/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 108s 766us/step - loss: 0.3489 - acc: 0.8406 - val_loss: 0.1317 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00014: loss improved from 0.35121 to 0.34888, saving model to results/dnn5/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 106s 758us/step - loss: 0.3492 - acc: 0.8401 - val_loss: 0.1294 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.34888\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.3491 - acc: 0.8401 - val_loss: 0.1247 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.34888\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 104s 743us/step - loss: 0.3482 - acc: 0.8408 - val_loss: 0.1260 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00017: loss improved from 0.34888 to 0.34824, saving model to results/dnn5/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.3537 - acc: 0.8397 - val_loss: 0.1315 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.34824\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 105s 746us/step - loss: 0.3463 - acc: 0.8419 - val_loss: 0.1233 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00019: loss improved from 0.34824 to 0.34629, saving model to results/dnn5/checkpoint-19.hdf5\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.3499 - acc: 0.8398 - val_loss: 0.1260 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.34629\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 107s 764us/step - loss: 0.3471 - acc: 0.8423 - val_loss: 0.1238 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.34629\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 109s 778us/step - loss: 0.3454 - acc: 0.8430 - val_loss: 0.1284 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00022: loss improved from 0.34629 to 0.34545, saving model to results/dnn5/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 110s 785us/step - loss: 0.3459 - acc: 0.8424 - val_loss: 0.1103 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.34545\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 111s 792us/step - loss: 0.3458 - acc: 0.8431 - val_loss: 0.1229 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.34545\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 109s 781us/step - loss: 0.3442 - acc: 0.8439 - val_loss: 0.1220 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00025: loss improved from 0.34545 to 0.34418, saving model to results/dnn5/checkpoint-25.hdf5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn5/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn5/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn5/dnn5_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "{'name': 'sequential_1', 'layers': [{'class_name': 'GRU', 'config': {'name': 'gru_1', 'trainable': True, 'batch_input_shape': (None, None, 43), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 4, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1, 'reset_after': False}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_1', 'trainable': True, 'activation': 'sigmoid'}}]}\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.5033 - acc: 0.7027 - val_loss: 0.1766 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86227, saving model to results/gru/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 12s 84us/step - loss: 0.4696 - acc: 0.7270 - val_loss: 0.1667 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86227 to 0.89130, saving model to results/gru/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4668 - acc: 0.7296 - val_loss: 0.1818 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89130\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 13s 90us/step - loss: 0.4641 - acc: 0.7314 - val_loss: 0.1694 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89130 to 0.90037, saving model to results/gru/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 14s 97us/step - loss: 0.4628 - acc: 0.7302 - val_loss: 0.1711 - val_acc: 0.8946\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90037\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4618 - acc: 0.7302 - val_loss: 0.1660 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90037 to 0.91137, saving model to results/gru/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4609 - acc: 0.7299 - val_loss: 0.1771 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91137\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4601 - acc: 0.7305 - val_loss: 0.1614 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91137 to 0.92110, saving model to results/gru/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 12s 84us/step - loss: 0.4596 - acc: 0.7290 - val_loss: 0.1537 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92110\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4585 - acc: 0.7312 - val_loss: 0.1719 - val_acc: 0.8964\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92110\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 12s 89us/step - loss: 0.4579 - acc: 0.7306 - val_loss: 0.1640 - val_acc: 0.9035\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92110\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 12s 86us/step - loss: 0.4571 - acc: 0.7327 - val_loss: 0.1635 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92110\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4565 - acc: 0.7328 - val_loss: 0.1501 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92110\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 12s 84us/step - loss: 0.4554 - acc: 0.7348 - val_loss: 0.1536 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.92110 to 0.92575, saving model to results/gru/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 13s 90us/step - loss: 0.4537 - acc: 0.7362 - val_loss: 0.1809 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92575\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 14s 103us/step - loss: 0.4515 - acc: 0.7408 - val_loss: 0.1645 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92575\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 0.4475 - acc: 0.7467 - val_loss: 0.1495 - val_acc: 0.9366\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.92575 to 0.93655, saving model to results/gru/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4424 - acc: 0.7567 - val_loss: 0.1726 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.93655 to 0.93949, saving model to results/gru/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.4360 - acc: 0.7642 - val_loss: 0.1549 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.93949 to 0.95318, saving model to results/gru/checkpoint-19.hdf5\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.4291 - acc: 0.7729 - val_loss: 0.1654 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.95318\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.4224 - acc: 0.7824 - val_loss: 0.1796 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.95318\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 19s 132us/step - loss: 0.4161 - acc: 0.7891 - val_loss: 0.1395 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.95318 to 0.99869, saving model to results/gru/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.4102 - acc: 0.7952 - val_loss: 0.1487 - val_acc: 0.9986\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99869\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 18s 128us/step - loss: 0.4054 - acc: 0.8013 - val_loss: 0.1783 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99869\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 18s 130us/step - loss: 0.4010 - acc: 0.8048 - val_loss: 0.1617 - val_acc: 0.9561\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99869\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "print(model.get_config())\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/gru/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/gru/gru_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(8, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.4878 - acc: 0.7141 - val_loss: 0.1687 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87989, saving model to results/gru1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 0.4659 - acc: 0.7283 - val_loss: 0.1901 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.87989\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.4634 - acc: 0.7302 - val_loss: 0.1956 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87989 to 0.88049, saving model to results/gru1/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.4613 - acc: 0.7326 - val_loss: 0.1687 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.88049 to 0.88511, saving model to results/gru1/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.4603 - acc: 0.7308 - val_loss: 0.1613 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.88511 to 0.91480, saving model to results/gru1/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.4595 - acc: 0.7323 - val_loss: 0.1720 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91480\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.4587 - acc: 0.7324 - val_loss: 0.1603 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91480\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4579 - acc: 0.7313 - val_loss: 0.1683 - val_acc: 0.9023\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91480\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.4566 - acc: 0.7335 - val_loss: 0.1646 - val_acc: 0.8933\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91480\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 15s 108us/step - loss: 0.4549 - acc: 0.7377 - val_loss: 0.1538 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91480\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 15s 108us/step - loss: 0.4474 - acc: 0.7494 - val_loss: 0.1417 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.91480 to 0.95346, saving model to results/gru1/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 15s 108us/step - loss: 0.4291 - acc: 0.7716 - val_loss: 0.1329 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.95346 to 0.99723, saving model to results/gru1/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 15s 109us/step - loss: 0.4069 - acc: 0.7900 - val_loss: 0.1423 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99723\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 15s 107us/step - loss: 0.3945 - acc: 0.8007 - val_loss: 0.1103 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99723 to 0.99806, saving model to results/gru1/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 25s 178us/step - loss: 0.3890 - acc: 0.8066 - val_loss: 0.1620 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99806\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 0.3878 - acc: 0.8071 - val_loss: 0.1415 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99806\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3846 - acc: 0.8112 - val_loss: 0.1877 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99806\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 0.3839 - acc: 0.8115 - val_loss: 0.1218 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99806\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3828 - acc: 0.8127 - val_loss: 0.1451 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99806\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3818 - acc: 0.8136 - val_loss: 0.1258 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99806\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 18s 129us/step - loss: 0.3808 - acc: 0.8146 - val_loss: 0.1340 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99806\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3803 - acc: 0.8142 - val_loss: 0.1100 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99806\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 14s 102us/step - loss: 0.3791 - acc: 0.8158 - val_loss: 0.1367 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99806\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 14s 100us/step - loss: 0.3787 - acc: 0.8166 - val_loss: 0.1649 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99806\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 14s 99us/step - loss: 0.3783 - acc: 0.8157 - val_loss: 0.1471 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99806\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/gru1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/gru1/gru1_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(16, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 24s 170us/step - loss: 0.4772 - acc: 0.7204 - val_loss: 0.1790 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88249, saving model to results/gru2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 20s 145us/step - loss: 0.4636 - acc: 0.7293 - val_loss: 0.1599 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88249 to 0.92090, saving model to results/gru2/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.4615 - acc: 0.7299 - val_loss: 0.1699 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92090\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.4599 - acc: 0.7309 - val_loss: 0.1708 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92090\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.4589 - acc: 0.7317 - val_loss: 0.1694 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92090\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 21s 152us/step - loss: 0.4569 - acc: 0.7323 - val_loss: 0.1547 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92090\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 22s 155us/step - loss: 0.4529 - acc: 0.7381 - val_loss: 0.1609 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92090\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 21s 152us/step - loss: 0.4403 - acc: 0.7548 - val_loss: 0.1446 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92090 to 0.99387, saving model to results/gru2/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 21s 151us/step - loss: 0.4122 - acc: 0.7823 - val_loss: 0.1320 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99387 to 0.99492, saving model to results/gru2/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 21s 151us/step - loss: 0.3967 - acc: 0.7957 - val_loss: 0.1354 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99492 to 0.99569, saving model to results/gru2/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 21s 147us/step - loss: 0.3903 - acc: 0.8021 - val_loss: 0.1302 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99569 to 0.99709, saving model to results/gru2/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 20s 144us/step - loss: 0.3856 - acc: 0.8078 - val_loss: 0.1159 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99709\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 19s 137us/step - loss: 0.3833 - acc: 0.8086 - val_loss: 0.1234 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99709\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 19s 137us/step - loss: 0.3810 - acc: 0.8129 - val_loss: 0.1043 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99709 to 0.99880, saving model to results/gru2/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 21s 147us/step - loss: 0.3790 - acc: 0.8147 - val_loss: 0.1040 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.99880 to 0.99929, saving model to results/gru2/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.3791 - acc: 0.8140 - val_loss: 0.1367 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99929\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3782 - acc: 0.8147 - val_loss: 0.1550 - val_acc: 0.9603\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99929\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3767 - acc: 0.8159 - val_loss: 0.1231 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99929\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 20s 146us/step - loss: 0.3753 - acc: 0.8188 - val_loss: 0.1222 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99929\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3752 - acc: 0.8191 - val_loss: 0.1712 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99929\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 23s 162us/step - loss: 0.3740 - acc: 0.8193 - val_loss: 0.1245 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99929\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 23s 161us/step - loss: 0.3728 - acc: 0.8199 - val_loss: 0.1212 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99929\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 23s 163us/step - loss: 0.3724 - acc: 0.8209 - val_loss: 0.1324 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99929\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3715 - acc: 0.8218 - val_loss: 0.1261 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99929\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.3704 - acc: 0.8232 - val_loss: 0.1362 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nloss, accuracy = model.evaluate(X_test, y_test)\\nprint(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\\ny_pred = model.predict_classes(X_test)\\nnp.savetxt(\\'results/gru2/gru2predicted.txt\\', np.transpose([y_test,y_pred]), fmt=\\'%01d\\')\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/gru2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis2.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/gru2/gru2_model.hdf5\")\n",
    "\n",
    "'''\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "np.savetxt('results/gru2/gru2predicted.txt', np.transpose([y_test,y_pred]), fmt='%01d')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(32, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 30s 211us/step - loss: 0.4742 - acc: 0.7196 - val_loss: 0.1975 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85583, saving model to results/gru3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 28s 199us/step - loss: 0.4629 - acc: 0.7285 - val_loss: 0.1606 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85583 to 0.95723, saving model to results/gru3/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 30s 211us/step - loss: 0.4590 - acc: 0.7304 - val_loss: 0.1690 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95723\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 28s 202us/step - loss: 0.4572 - acc: 0.7299 - val_loss: 0.1701 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95723\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 28s 201us/step - loss: 0.4563 - acc: 0.7304 - val_loss: 0.1486 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95723\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 26s 185us/step - loss: 0.4555 - acc: 0.7316 - val_loss: 0.1864 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95723\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 26s 187us/step - loss: 0.4548 - acc: 0.7307 - val_loss: 0.1887 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95723\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 26s 185us/step - loss: 0.4537 - acc: 0.7317 - val_loss: 0.1828 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95723\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 27s 194us/step - loss: 0.4515 - acc: 0.7347 - val_loss: 0.1555 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95723\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 28s 203us/step - loss: 0.4359 - acc: 0.7558 - val_loss: 0.1738 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95723\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 29s 204us/step - loss: 0.4058 - acc: 0.7871 - val_loss: 0.1311 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.95723 to 0.99755, saving model to results/gru3/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 28s 202us/step - loss: 0.3932 - acc: 0.7983 - val_loss: 0.1516 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99755\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 29s 205us/step - loss: 0.3869 - acc: 0.8044 - val_loss: 0.1049 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.99755 to 0.99837, saving model to results/gru3/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 29s 207us/step - loss: 0.3821 - acc: 0.8101 - val_loss: 0.1784 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99837\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 29s 206us/step - loss: 0.3785 - acc: 0.8133 - val_loss: 0.1254 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.99837 to 0.99866, saving model to results/gru3/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 28s 201us/step - loss: 0.3776 - acc: 0.8134 - val_loss: 0.1439 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99866\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 27s 195us/step - loss: 0.3740 - acc: 0.8180 - val_loss: 0.1296 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.99866 to 0.99954, saving model to results/gru3/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 28s 197us/step - loss: 0.3732 - acc: 0.8191 - val_loss: 0.1359 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99954\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 28s 198us/step - loss: 0.3694 - acc: 0.8218 - val_loss: 0.1358 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99954\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 27s 192us/step - loss: 0.3683 - acc: 0.8235 - val_loss: 0.1402 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99954\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 26s 187us/step - loss: 0.3667 - acc: 0.8245 - val_loss: 0.1110 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99954\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 27s 195us/step - loss: 0.3640 - acc: 0.8267 - val_loss: 0.1321 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99954\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 28s 201us/step - loss: 0.3594 - acc: 0.8314 - val_loss: 0.1325 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99954\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 28s 203us/step - loss: 0.3565 - acc: 0.8338 - val_loss: 0.1270 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99954\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 29s 207us/step - loss: 0.3541 - acc: 0.8363 - val_loss: 0.1102 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99954\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/gru3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/gru3/gru3_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_5', 'layers': [{'class_name': 'LSTM', 'config': {'name': 'lstm_1', 'trainable': True, 'batch_input_shape': (None, None, 43), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 4, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_5', 'trainable': True, 'activation': 'sigmoid'}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 0.5036 - acc: 0.7034 - val_loss: 0.1767 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87063, saving model to results/lstm/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4696 - acc: 0.7265 - val_loss: 0.1559 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87063 to 0.92061, saving model to results/lstm/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4666 - acc: 0.7281 - val_loss: 0.1779 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92061\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4646 - acc: 0.7295 - val_loss: 0.1747 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92061\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 12s 85us/step - loss: 0.4636 - acc: 0.7285 - val_loss: 0.1699 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92061\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 12s 84us/step - loss: 0.4621 - acc: 0.7301 - val_loss: 0.1657 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92061\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 12s 85us/step - loss: 0.4609 - acc: 0.7294 - val_loss: 0.1643 - val_acc: 0.8989\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92061\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 12s 85us/step - loss: 0.4598 - acc: 0.7306 - val_loss: 0.1534 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92061 to 0.92218, saving model to results/lstm/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 13s 89us/step - loss: 0.4592 - acc: 0.7299 - val_loss: 0.1820 - val_acc: 0.9027\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92218\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4584 - acc: 0.7305 - val_loss: 0.1697 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92218\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4576 - acc: 0.7310 - val_loss: 0.1631 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92218 to 0.93276, saving model to results/lstm/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 13s 90us/step - loss: 0.4572 - acc: 0.7299 - val_loss: 0.1572 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93276\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 12s 86us/step - loss: 0.4567 - acc: 0.7303 - val_loss: 0.1828 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93276\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4559 - acc: 0.7303 - val_loss: 0.1808 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93276\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4554 - acc: 0.7306 - val_loss: 0.1890 - val_acc: 0.8912\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93276\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 12s 86us/step - loss: 0.4548 - acc: 0.7326 - val_loss: 0.1690 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93276\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 13s 93us/step - loss: 0.4550 - acc: 0.7310 - val_loss: 0.1658 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93276\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 13s 92us/step - loss: 0.4542 - acc: 0.7313 - val_loss: 0.1674 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93276\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 14s 98us/step - loss: 0.4542 - acc: 0.7323 - val_loss: 0.1623 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93276\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 13s 95us/step - loss: 0.4537 - acc: 0.7322 - val_loss: 0.1713 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93276\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4531 - acc: 0.7315 - val_loss: 0.1662 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93276\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4524 - acc: 0.7343 - val_loss: 0.1573 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93276\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4509 - acc: 0.7371 - val_loss: 0.1583 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.93276 to 0.93305, saving model to results/lstm/checkpoint-23.hdf5\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 13s 93us/step - loss: 0.4481 - acc: 0.7424 - val_loss: 0.1561 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.93305 to 0.93966, saving model to results/lstm/checkpoint-24.hdf5\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 13s 94us/step - loss: 0.4459 - acc: 0.7475 - val_loss: 0.1756 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93966\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "#print(X_train.shape)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "print(model.get_config())\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/lstm/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm/lstm_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(8, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 22s 156us/step - loss: 0.4939 - acc: 0.7081 - val_loss: 0.1722 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86552, saving model to results/lstm1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4663 - acc: 0.7283 - val_loss: 0.1702 - val_acc: 0.8965\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86552 to 0.89646, saving model to results/lstm1/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.4629 - acc: 0.7303 - val_loss: 0.1735 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89646\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.4608 - acc: 0.7309 - val_loss: 0.1679 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89646\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.4580 - acc: 0.7348 - val_loss: 0.1508 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.89646 to 0.97739, saving model to results/lstm1/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.4514 - acc: 0.7444 - val_loss: 0.1645 - val_acc: 0.8988\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97739\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.4291 - acc: 0.7705 - val_loss: 0.1471 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.97739 to 0.99316, saving model to results/lstm1/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.4082 - acc: 0.7885 - val_loss: 0.1128 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99316 to 0.99812, saving model to results/lstm1/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3985 - acc: 0.7976 - val_loss: 0.1286 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99812\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3944 - acc: 0.7994 - val_loss: 0.1368 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99812\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 18s 132us/step - loss: 0.3910 - acc: 0.8018 - val_loss: 0.1595 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99812\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 18s 131us/step - loss: 0.3894 - acc: 0.8038 - val_loss: 0.1550 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99812\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.3885 - acc: 0.8043 - val_loss: 0.1044 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99812\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 20s 141us/step - loss: 0.3875 - acc: 0.8060 - val_loss: 0.1271 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99812\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 20s 142us/step - loss: 0.3864 - acc: 0.8071 - val_loss: 0.1245 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99812\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 21s 147us/step - loss: 0.3858 - acc: 0.8077 - val_loss: 0.1234 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99812\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 20s 146us/step - loss: 0.3855 - acc: 0.8070 - val_loss: 0.1279 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99812\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 19s 138us/step - loss: 0.3844 - acc: 0.8091 - val_loss: 0.1197 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99812\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.3851 - acc: 0.8078 - val_loss: 0.1463 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99812\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 19s 134us/step - loss: 0.3843 - acc: 0.8083 - val_loss: 0.1194 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99812\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.3834 - acc: 0.8093 - val_loss: 0.0996 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.99812 to 0.99818, saving model to results/lstm1/checkpoint-21.hdf5\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 18s 131us/step - loss: 0.3839 - acc: 0.8084 - val_loss: 0.1135 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99818\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 0.3836 - acc: 0.8098 - val_loss: 0.1007 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99818\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3825 - acc: 0.8114 - val_loss: 0.1549 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99818\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3823 - acc: 0.8104 - val_loss: 0.1563 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99818\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/lstm1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm1/lstm1_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(16, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 31s 223us/step - loss: 0.4810 - acc: 0.7170 - val_loss: 0.1539 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93407, saving model to results/lstm2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 26s 188us/step - loss: 0.4642 - acc: 0.7283 - val_loss: 0.1572 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93407\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 27s 191us/step - loss: 0.4619 - acc: 0.7303 - val_loss: 0.1983 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93407\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 26s 182us/step - loss: 0.4590 - acc: 0.7316 - val_loss: 0.1599 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93407\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 26s 183us/step - loss: 0.4565 - acc: 0.7335 - val_loss: 0.1565 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93407\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 26s 183us/step - loss: 0.4494 - acc: 0.7447 - val_loss: 0.1603 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93407\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 25s 176us/step - loss: 0.4180 - acc: 0.7765 - val_loss: 0.1389 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.93407 to 0.99632, saving model to results/lstm2/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 26s 184us/step - loss: 0.3975 - acc: 0.7950 - val_loss: 0.1045 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99632 to 0.99877, saving model to results/lstm2/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 26s 185us/step - loss: 0.3911 - acc: 0.8027 - val_loss: 0.1291 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99877\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 27s 193us/step - loss: 0.3871 - acc: 0.8044 - val_loss: 0.1737 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99877\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 27s 194us/step - loss: 0.3835 - acc: 0.8090 - val_loss: 0.1066 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99877\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 30s 212us/step - loss: 0.3808 - acc: 0.8109 - val_loss: 0.1172 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99877\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 33s 232us/step - loss: 0.3795 - acc: 0.8127 - val_loss: 0.1436 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99877\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 30s 211us/step - loss: 0.3770 - acc: 0.8156 - val_loss: 0.1241 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99877\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 29s 207us/step - loss: 0.3759 - acc: 0.8158 - val_loss: 0.1355 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99877\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 33s 234us/step - loss: 0.3759 - acc: 0.8158 - val_loss: 0.1315 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99877\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 28s 199us/step - loss: 0.3746 - acc: 0.8164 - val_loss: 0.1475 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99877\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 29s 210us/step - loss: 0.3741 - acc: 0.8183 - val_loss: 0.1438 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99877\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 32s 231us/step - loss: 0.3732 - acc: 0.8183 - val_loss: 0.1163 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99877\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 29s 208us/step - loss: 0.3733 - acc: 0.8176 - val_loss: 0.1371 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99877\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 28s 203us/step - loss: 0.3721 - acc: 0.8197 - val_loss: 0.1421 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99877\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 29s 206us/step - loss: 0.3716 - acc: 0.8196 - val_loss: 0.1334 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99877\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 27s 193us/step - loss: 0.3713 - acc: 0.8195 - val_loss: 0.1335 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99877\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 29s 204us/step - loss: 0.3710 - acc: 0.8212 - val_loss: 0.1154 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.99877 to 0.99903, saving model to results/lstm2/checkpoint-24.hdf5\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 29s 208us/step - loss: 0.3706 - acc: 0.8210 - val_loss: 0.1284 - val_acc: 0.9986\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99903\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/lstm2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm2/lstm2_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(32, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 47s 336us/step - loss: 0.4767 - acc: 0.7190 - val_loss: 0.1777 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88178, saving model to results/lstm3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 37s 262us/step - loss: 0.4630 - acc: 0.7293 - val_loss: 0.1671 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88178 to 0.91551, saving model to results/lstm3/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 36s 254us/step - loss: 0.4598 - acc: 0.7310 - val_loss: 0.1665 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91551 to 0.92680, saving model to results/lstm3/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 31s 223us/step - loss: 0.4580 - acc: 0.7294 - val_loss: 0.1612 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92680\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 34s 244us/step - loss: 0.4563 - acc: 0.7295 - val_loss: 0.1368 - val_acc: 0.9996\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92680 to 0.99960, saving model to results/lstm3/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.4555 - acc: 0.7302 - val_loss: 0.1670 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99960\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 43s 305us/step - loss: 0.4544 - acc: 0.7317 - val_loss: 0.1468 - val_acc: 0.9438\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99960\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 37s 266us/step - loss: 0.4525 - acc: 0.7332 - val_loss: 0.1716 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99960\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 36s 254us/step - loss: 0.4332 - acc: 0.7586 - val_loss: 0.1403 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99960\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 35s 250us/step - loss: 0.3992 - acc: 0.7918 - val_loss: 0.1437 - val_acc: 0.9402\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99960\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 35s 246us/step - loss: 0.3880 - acc: 0.8022 - val_loss: 0.1356 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99960\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 36s 255us/step - loss: 0.3855 - acc: 0.8066 - val_loss: 0.1206 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99960\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 37s 263us/step - loss: 0.3818 - acc: 0.8088 - val_loss: 0.1380 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99960\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 36s 255us/step - loss: 0.3804 - acc: 0.8100 - val_loss: 0.1369 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99960\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 34s 239us/step - loss: 0.3786 - acc: 0.8124 - val_loss: 0.1220 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99960\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 35s 246us/step - loss: 0.3782 - acc: 0.8128 - val_loss: 0.1300 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99960\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 33s 237us/step - loss: 0.3774 - acc: 0.8130 - val_loss: 0.1541 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99960\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 36s 255us/step - loss: 0.3761 - acc: 0.8145 - val_loss: 0.1988 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99960\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 34s 241us/step - loss: 0.3746 - acc: 0.8149 - val_loss: 0.1513 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99960\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 31s 219us/step - loss: 0.3742 - acc: 0.8154 - val_loss: 0.1299 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99960\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 31s 219us/step - loss: 0.3738 - acc: 0.8159 - val_loss: 0.1314 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99960\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 31s 223us/step - loss: 0.3730 - acc: 0.8169 - val_loss: 0.1330 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99960\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 32s 228us/step - loss: 0.3722 - acc: 0.8172 - val_loss: 0.1305 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99960\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 35s 250us/step - loss: 0.3712 - acc: 0.8192 - val_loss: 0.1445 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99960\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 33s 234us/step - loss: 0.3707 - acc: 0.8195 - val_loss: 0.1345 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99960\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/lstm3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm3/lstm3_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140272, 1, 43)\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_1', 'layers': [{'class_name': 'SimpleRNN', 'config': {'name': 'simple_rnn_1', 'trainable': True, 'batch_input_shape': (None, None, 43), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 4, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_1', 'trainable': True, 'activation': 'sigmoid'}}]}\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 10s 73us/step - loss: 0.5011 - acc: 0.7052 - val_loss: 0.1783 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85822, saving model to results/rnn/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 9s 65us/step - loss: 0.4696 - acc: 0.7275 - val_loss: 0.1640 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85822 to 0.92267, saving model to results/rnn/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 9s 64us/step - loss: 0.4672 - acc: 0.7287 - val_loss: 0.1539 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92267\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 9s 67us/step - loss: 0.4649 - acc: 0.7297 - val_loss: 0.1675 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92267\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.4637 - acc: 0.7292 - val_loss: 0.1726 - val_acc: 0.9024\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92267\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 10s 73us/step - loss: 0.4626 - acc: 0.7302 - val_loss: 0.1600 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92267 to 0.92272, saving model to results/rnn/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 10s 74us/step - loss: 0.4620 - acc: 0.7302 - val_loss: 0.1684 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92272\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 11s 76us/step - loss: 0.4612 - acc: 0.7303 - val_loss: 0.1741 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92272\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 10s 73us/step - loss: 0.4605 - acc: 0.7308 - val_loss: 0.1586 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92272\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 10s 70us/step - loss: 0.4602 - acc: 0.7305 - val_loss: 0.1864 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92272\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 10s 73us/step - loss: 0.4594 - acc: 0.7316 - val_loss: 0.1648 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92272\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 10s 74us/step - loss: 0.4585 - acc: 0.7318 - val_loss: 0.1660 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92272\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 10s 70us/step - loss: 0.4581 - acc: 0.7338 - val_loss: 0.1573 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92272 to 0.92791, saving model to results/rnn/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4563 - acc: 0.7359 - val_loss: 0.1551 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92791\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.4545 - acc: 0.7391 - val_loss: 0.1622 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92791\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4530 - acc: 0.7422 - val_loss: 0.1702 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92791\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.4503 - acc: 0.7470 - val_loss: 0.1557 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.92791 to 0.97448, saving model to results/rnn/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 10s 68us/step - loss: 0.4484 - acc: 0.7509 - val_loss: 0.1562 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.97448\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 9s 65us/step - loss: 0.4459 - acc: 0.7538 - val_loss: 0.1664 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.97448\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.4435 - acc: 0.7585 - val_loss: 0.1693 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97448\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.4406 - acc: 0.7638 - val_loss: 0.1598 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.97448\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 9s 67us/step - loss: 0.4386 - acc: 0.7666 - val_loss: 0.1378 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.97448 to 0.99869, saving model to results/rnn/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 11s 78us/step - loss: 0.4356 - acc: 0.7704 - val_loss: 0.1999 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99869\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.4335 - acc: 0.7749 - val_loss: 0.1598 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99869\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.4313 - acc: 0.7777 - val_loss: 0.1506 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99869\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "print(model.get_config())\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/rnn/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/rnn/rnn_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(8, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 15s 109us/step - loss: 0.4859 - acc: 0.7116 - val_loss: 0.1790 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85571, saving model to results/rnn1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 15s 105us/step - loss: 0.4664 - acc: 0.7274 - val_loss: 0.1758 - val_acc: 0.8741\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85571 to 0.87413, saving model to results/rnn1/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 14s 103us/step - loss: 0.4635 - acc: 0.7295 - val_loss: 0.1479 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87413 to 0.92358, saving model to results/rnn1/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 14s 102us/step - loss: 0.4618 - acc: 0.7299 - val_loss: 0.1452 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92358 to 0.92466, saving model to results/rnn1/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 15s 108us/step - loss: 0.4607 - acc: 0.7302 - val_loss: 0.1543 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92466\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 0.4602 - acc: 0.7318 - val_loss: 0.1804 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92466\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.4596 - acc: 0.7309 - val_loss: 0.1993 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92466\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 15s 109us/step - loss: 0.4596 - acc: 0.7313 - val_loss: 0.1709 - val_acc: 0.8815\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92466\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 14s 97us/step - loss: 0.4590 - acc: 0.7323 - val_loss: 0.1616 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92466\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 13s 93us/step - loss: 0.4583 - acc: 0.7323 - val_loss: 0.1586 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92466 to 0.93088, saving model to results/rnn1/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 13s 94us/step - loss: 0.4583 - acc: 0.7322 - val_loss: 0.1602 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93088\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4582 - acc: 0.7312 - val_loss: 0.1759 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93088\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 12s 85us/step - loss: 0.4578 - acc: 0.7312 - val_loss: 0.1322 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.93088 to 0.99949, saving model to results/rnn1/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4577 - acc: 0.7331 - val_loss: 0.1804 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99949\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 11s 82us/step - loss: 0.4567 - acc: 0.7338 - val_loss: 0.2005 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99949\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 11s 79us/step - loss: 0.4555 - acc: 0.7355 - val_loss: 0.1398 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99949\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4501 - acc: 0.7458 - val_loss: 0.1756 - val_acc: 0.8786\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99949\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4332 - acc: 0.7688 - val_loss: 0.1764 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99949\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4120 - acc: 0.7912 - val_loss: 0.1300 - val_acc: 0.9970\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99949\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 10s 74us/step - loss: 0.4003 - acc: 0.7992 - val_loss: 0.1606 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99949\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 10s 74us/step - loss: 0.3937 - acc: 0.8044 - val_loss: 0.0748 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99949\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 11s 77us/step - loss: 0.3906 - acc: 0.8074 - val_loss: 0.1926 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99949\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 11s 81us/step - loss: 0.3881 - acc: 0.8105 - val_loss: 0.1285 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99949\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.3864 - acc: 0.8109 - val_loss: 0.1130 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99949\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 13s 96us/step - loss: 0.3847 - acc: 0.8139 - val_loss: 0.1847 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99949\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/rnn1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/rnn1/rnn1_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(16, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4768 - acc: 0.7190 - val_loss: 0.1766 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87667, saving model to results/rnn2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.4650 - acc: 0.7277 - val_loss: 0.1740 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87667 to 0.90165, saving model to results/rnn2/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.4627 - acc: 0.7307 - val_loss: 0.1943 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90165 to 0.92324, saving model to results/rnn2/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 15s 105us/step - loss: 0.4613 - acc: 0.7298 - val_loss: 0.1625 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92324\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 14s 99us/step - loss: 0.4601 - acc: 0.7316 - val_loss: 0.1699 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92324\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 14s 98us/step - loss: 0.4598 - acc: 0.7308 - val_loss: 0.1885 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92324\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 14s 100us/step - loss: 0.4585 - acc: 0.7321 - val_loss: 0.1683 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92324\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 14s 99us/step - loss: 0.4563 - acc: 0.7357 - val_loss: 0.1559 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92324\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 14s 103us/step - loss: 0.4322 - acc: 0.7647 - val_loss: 0.1343 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92324 to 0.99592, saving model to results/rnn2/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 14s 103us/step - loss: 0.4048 - acc: 0.7895 - val_loss: 0.1420 - val_acc: 0.9976\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99592 to 0.99758, saving model to results/rnn2/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 14s 101us/step - loss: 0.3964 - acc: 0.7971 - val_loss: 0.1259 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99758 to 0.99792, saving model to results/rnn2/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 0.3910 - acc: 0.8019 - val_loss: 0.1102 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.99792 to 0.99872, saving model to results/rnn2/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3895 - acc: 0.8039 - val_loss: 0.1059 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99872\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3877 - acc: 0.8062 - val_loss: 0.0880 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99872 to 0.99883, saving model to results/rnn2/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3862 - acc: 0.8077 - val_loss: 0.1437 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99883\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3847 - acc: 0.8097 - val_loss: 0.1745 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99883\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3854 - acc: 0.8082 - val_loss: 0.1074 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99883\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3829 - acc: 0.8115 - val_loss: 0.1424 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99883\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3831 - acc: 0.8124 - val_loss: 0.1049 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99883\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 0.3820 - acc: 0.8144 - val_loss: 0.1309 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99883\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3812 - acc: 0.8146 - val_loss: 0.0848 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99883\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 0.3809 - acc: 0.8150 - val_loss: 0.1344 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99883\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3798 - acc: 0.8166 - val_loss: 0.1775 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99883\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 15s 106us/step - loss: 0.3794 - acc: 0.8173 - val_loss: 0.1129 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99883\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 15s 106us/step - loss: 0.3790 - acc: 0.8177 - val_loss: 0.1105 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99883\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/rnn2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/rnn2/rnn2_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(32, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.4752 - acc: 0.7188 - val_loss: 0.1480 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97548, saving model to results/rnn3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4652 - acc: 0.7297 - val_loss: 0.1630 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.97548\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4627 - acc: 0.7299 - val_loss: 0.1696 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.97548\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 20s 142us/step - loss: 0.4610 - acc: 0.7320 - val_loss: 0.1623 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97548\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 19s 134us/step - loss: 0.4596 - acc: 0.7310 - val_loss: 0.1657 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97548\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4577 - acc: 0.7337 - val_loss: 0.1784 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97548\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 18s 129us/step - loss: 0.4557 - acc: 0.7389 - val_loss: 0.1944 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97548\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 19s 135us/step - loss: 0.4512 - acc: 0.7442 - val_loss: 0.1317 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.97548 to 0.99892, saving model to results/rnn3/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4319 - acc: 0.7626 - val_loss: 0.1550 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99892\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4042 - acc: 0.7863 - val_loss: 0.1205 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99892 to 0.99897, saving model to results/rnn3/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 19s 134us/step - loss: 0.3969 - acc: 0.7931 - val_loss: 0.1119 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99897\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 23s 163us/step - loss: 0.3958 - acc: 0.7944 - val_loss: 0.1587 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99897\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 24s 172us/step - loss: 0.3915 - acc: 0.7992 - val_loss: 0.1478 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99897\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 26s 184us/step - loss: 0.3903 - acc: 0.8006 - val_loss: 0.1245 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99897 to 0.99900, saving model to results/rnn3/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 23s 165us/step - loss: 0.3889 - acc: 0.8029 - val_loss: 0.1443 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99900\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 21s 151us/step - loss: 0.3871 - acc: 0.8054 - val_loss: 0.1390 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99900\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 21s 147us/step - loss: 0.3863 - acc: 0.8060 - val_loss: 0.0985 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.99900 to 0.99943, saving model to results/rnn3/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 22s 155us/step - loss: 0.3858 - acc: 0.8071 - val_loss: 0.1293 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99943\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.3854 - acc: 0.8075 - val_loss: 0.1657 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99943\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.3846 - acc: 0.8093 - val_loss: 0.1241 - val_acc: 0.9976\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99943\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 22s 154us/step - loss: 0.3834 - acc: 0.8108 - val_loss: 0.1241 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99943\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 22s 154us/step - loss: 0.3822 - acc: 0.8112 - val_loss: 0.1165 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99943\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 21s 148us/step - loss: 0.3818 - acc: 0.8120 - val_loss: 0.1129 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99943\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 22s 159us/step - loss: 0.3819 - acc: 0.8127 - val_loss: 0.1489 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99943\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 22s 159us/step - loss: 0.3814 - acc: 0.8137 - val_loss: 0.1312 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99943\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/rnn3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/rnn3/rnn3_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:65: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:78: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 113s 803us/step - loss: 0.4829 - acc: 0.7264 - val_loss: 0.1658 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90610, saving model to results/cnn-gru1results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 114s 810us/step - loss: 0.4248 - acc: 0.7779 - val_loss: 0.1399 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90610 to 0.98885, saving model to results/cnn-gru1results/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 121s 864us/step - loss: 0.4152 - acc: 0.7864 - val_loss: 0.1396 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98885\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 121s 861us/step - loss: 0.4098 - acc: 0.7933 - val_loss: 0.1629 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98885\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 97s 689us/step - loss: 0.4065 - acc: 0.7956 - val_loss: 0.1244 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98885\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 90s 644us/step - loss: 0.4043 - acc: 0.7976 - val_loss: 0.1591 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98885\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 97s 690us/step - loss: 0.4039 - acc: 0.7984 - val_loss: 0.1473 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98885\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 100s 712us/step - loss: 0.4024 - acc: 0.7989 - val_loss: 0.1326 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98885\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 95s 675us/step - loss: 0.4002 - acc: 0.7992 - val_loss: 0.1551 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98885\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 94s 673us/step - loss: 0.3983 - acc: 0.8005 - val_loss: 0.1359 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98885\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 99s 709us/step - loss: 0.3971 - acc: 0.8013 - val_loss: 0.1372 - val_acc: 0.9678\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98885\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 100s 713us/step - loss: 0.3988 - acc: 0.8005 - val_loss: 0.1447 - val_acc: 0.9623 0.8 - ETA: 9s - lo - ETA: 7s -  - E - \n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98885\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 101s 724us/step - loss: 0.3973 - acc: 0.8009 - val_loss: 0.1550 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98885\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 93s 666us/step - loss: 0.3959 - acc: 0.8016 - val_loss: 0.1541 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98885\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 95s 677us/step - loss: 0.3949 - acc: 0.8016 - val_loss: 0.1710 - val_acc: 0.9636\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98885\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 96s 684us/step - loss: 0.3947 - acc: 0.8017 - val_loss: 0.1350 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98885\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 101s 718us/step - loss: 0.3931 - acc: 0.8032 - val_loss: 0.1323 - val_acc: 0.9597\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98885\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 100s 711us/step - loss: 0.3861 - acc: 0.8117 - val_loss: 0.1179 - val_acc: 0.9977s - loss: 0.3861 - acc: 0.\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.98885 to 0.99775, saving model to results/cnn-gru1results/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 92s 659us/step - loss: 0.3486 - acc: 0.8417 - val_loss: 0.1302 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99775\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 85s 608us/step - loss: 0.3392 - acc: 0.8491 - val_loss: 0.1233 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99775\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 76s 542us/step - loss: 0.3338 - acc: 0.8535 - val_loss: 0.1362 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99775\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 80s 571us/step - loss: 0.3315 - acc: 0.8555 - val_loss: 0.1188 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99775\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 83s 590us/step - loss: 0.3272 - acc: 0.8598 - val_loss: 0.1191 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99775\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 84s 597us/step - loss: 0.3245 - acc: 0.8611 - val_loss: 0.1287 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.99775 to 0.99866, saving model to results/cnn-gru1results/checkpoint-24.hdf5\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 82s 583us/step - loss: 0.3252 - acc: 0.8603 - val_loss: 0.1412 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99866\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import GRU, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru1results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru1results/cnntrainanalysis1.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru1results/cnn_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:65: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:67: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 43, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               172160    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 172,545\n",
      "Trainable params: 172,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 34s 239us/step - loss: 0.4558 - acc: 0.7482 - val_loss: 0.1593 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98426, saving model to results/cnn1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 33s 236us/step - loss: 0.4217 - acc: 0.7773 - val_loss: 0.1436 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.98426 to 0.98968, saving model to results/cnn1/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 32s 230us/step - loss: 0.4140 - acc: 0.7827 - val_loss: 0.1365 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.98968 to 0.99062, saving model to results/cnn1/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 33s 232us/step - loss: 0.4101 - acc: 0.7869 - val_loss: 0.1783 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99062\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 33s 232us/step - loss: 0.4075 - acc: 0.7887 - val_loss: 0.1551 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99062\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 33s 235us/step - loss: 0.4060 - acc: 0.7908 - val_loss: 0.1415 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99062\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 36s 259us/step - loss: 0.4030 - acc: 0.7923 - val_loss: 0.1472 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99062\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 34s 243us/step - loss: 0.4008 - acc: 0.7958 - val_loss: 0.1497 - val_acc: 0.9614\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99062\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 35s 246us/step - loss: 0.3986 - acc: 0.7974 - val_loss: 0.1467 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99062\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 34s 240us/step - loss: 0.3971 - acc: 0.7995 - val_loss: 0.1604 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99062\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 35s 247us/step - loss: 0.3956 - acc: 0.8017 - val_loss: 0.1288 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99062\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 35s 247us/step - loss: 0.3930 - acc: 0.8043 - val_loss: 0.1528 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99062\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 35s 247us/step - loss: 0.3916 - acc: 0.8077 - val_loss: 0.1370 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99062\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 34s 246us/step - loss: 0.3884 - acc: 0.8105 - val_loss: 0.1394 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99062\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 40s 288us/step - loss: 0.3842 - acc: 0.8152 - val_loss: 0.1245 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99062\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 36s 256us/step - loss: 0.3783 - acc: 0.8187 - val_loss: 0.1256 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.99062 to 0.99170, saving model to results/cnn1/checkpoint-16.hdf5\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 37s 265us/step - loss: 0.3734 - acc: 0.8233 - val_loss: 0.1320 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99170\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 39s 275us/step - loss: 0.3683 - acc: 0.8283 - val_loss: 0.1073 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.99170 to 0.99626, saving model to results/cnn1/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 39s 282us/step - loss: 0.3616 - acc: 0.8340 - val_loss: 0.1255 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99626\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 41s 292us/step - loss: 0.3572 - acc: 0.8368 - val_loss: 0.1204 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.99626 to 0.99635, saving model to results/cnn1/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 57s 403us/step - loss: 0.3529 - acc: 0.8398 - val_loss: 0.1287 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99635\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 44s 314us/step - loss: 0.3506 - acc: 0.8413 - val_loss: 0.1390 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99635\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 44s 317us/step - loss: 0.3496 - acc: 0.8418 - val_loss: 0.1269 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99635\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 47s 333us/step - loss: 0.3474 - acc: 0.8428 - val_loss: 0.1334 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99635\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 49s 349us/step - loss: 0.3464 - acc: 0.8441 - val_loss: 0.1506 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99635\n"
=======
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 101s 717us/step - loss: 0.4667 - acc: 0.7453 - val_loss: 0.1304 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94876, saving model to results/cnn-gru2results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 99s 708us/step - loss: 0.4153 - acc: 0.7902 - val_loss: 0.1466 - val_acc: 0.9566\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94876 to 0.95660, saving model to results/cnn-gru2results/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 100s 713us/step - loss: 0.4067 - acc: 0.7960 - val_loss: 0.1422 - val_acc: 0.9594\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.95660 to 0.95939, saving model to results/cnn-gru2results/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 104s 742us/step - loss: 0.4016 - acc: 0.7982 - val_loss: 0.1532 - val_acc: 0.9731\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95939 to 0.97305, saving model to results/cnn-gru2results/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 99s 709us/step - loss: 0.3969 - acc: 0.8021 - val_loss: 0.1457 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97305\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 102s 728us/step - loss: 0.3618 - acc: 0.8270 - val_loss: 0.0724 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.97305 to 0.99669, saving model to results/cnn-gru2results/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 99s 705us/step - loss: 0.3245 - acc: 0.8423 - val_loss: 0.0823 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99669\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 110s 781us/step - loss: 0.3117 - acc: 0.8457 - val_loss: 0.0788 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99669\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 110s 786us/step - loss: 0.3079 - acc: 0.8471 - val_loss: 0.0817 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99669\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 97s 690us/step - loss: 0.3065 - acc: 0.8478 - val_loss: 0.1125 - val_acc: 0.9940 l\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99669\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 98s 695us/step - loss: 0.3040 - acc: 0.8479 - val_loss: 0.0784 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99669\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 104s 741us/step - loss: 0.3018 - acc: 0.8491 - val_loss: 0.0789 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99669\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.3029 - acc: 0.8488 - val_loss: 0.0785 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99669\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 102s 725us/step - loss: 0.3013 - acc: 0.8494 - val_loss: 0.0792 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99669\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 103s 732us/step - loss: 0.2985 - acc: 0.8503 - val_loss: 0.0716 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99669\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 108s 768us/step - loss: 0.2977 - acc: 0.8512 - val_loss: 0.0696 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99669\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 100s 712us/step - loss: 0.2954 - acc: 0.8515 - val_loss: 0.0784 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99669\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 119s 845us/step - loss: 0.2979 - acc: 0.8499 - val_loss: 0.0778 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99669\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 103s 738us/step - loss: 0.2974 - acc: 0.8514 - val_loss: 0.0764 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99669\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 97s 689us/step - loss: 0.3247 - acc: 0.8398 - val_loss: 0.1293 - val_acc: 0.99773246 - acc: 0.83\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.99669 to 0.99766, saving model to results/cnn-gru2results/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 100s 713us/step - loss: 0.3076 - acc: 0.8488 - val_loss: 0.1059 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99766\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 99s 707us/step - loss: 0.3005 - acc: 0.8501 - val_loss: 0.0765 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99766\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 103s 735us/step - loss: 0.2972 - acc: 0.8507 - val_loss: 0.0730 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99766\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 98s 695us/step - loss: 0.2970 - acc: 0.8508 - val_loss: 0.0750 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99766\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 106s 753us/step - loss: 0.2941 - acc: 0.8516 - val_loss: 0.0749 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99766\n"
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "#CNN1\n",
=======
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
<<<<<<< HEAD
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
=======
    "from keras.layers import GRU, GRU, SimpleRNN\n",
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "\n",
    "\n",
    "lstm_output_size = 128\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "print(cnn.summary())\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
=======
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
<<<<<<< HEAD
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn1/cnntrainanalysis1.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn1/cnn_model.hdf5\")\n"
=======
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru2results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru2results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru2results/cnn_model.hdf5\")\n"
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 8,
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:83: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
=======
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
<<<<<<< HEAD
      "140272/140272 [==============================] - 66s 473us/step - loss: 0.4342 - acc: 0.7678 - val_loss: 0.1594 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97148, saving model to results/cnn2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 59s 418us/step - loss: 0.3785 - acc: 0.8219 - val_loss: 0.1087 - val_acc: 0.9925cc: - ETA: 6s - loss: - ETA: 0s - loss: 0.3786 - acc: \n",
      "\n",
      "Epoch 00002: val_acc improved from 0.97148 to 0.99247, saving model to results/cnn2/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 62s 442us/step - loss: 0.3439 - acc: 0.8428 - val_loss: 0.0990 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.99247 to 0.99250, saving model to results/cnn2/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 62s 443us/step - loss: 0.3354 - acc: 0.8445 - val_loss: 0.1434 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99250\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 84s 599us/step - loss: 0.3310 - acc: 0.8453 - val_loss: 0.1367 - val_acc: 0.9926 0s - loss: 0.3310 - acc: 0.8\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.99250 to 0.99264, saving model to results/cnn2/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 91s 648us/step - loss: 0.3188 - acc: 0.8460 - val_loss: 0.0937 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99264\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 96s 683us/step - loss: 0.3128 - acc: 0.8469 - val_loss: 0.1687 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.99264 to 0.99410, saving model to results/cnn2/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 93s 666us/step - loss: 0.3076 - acc: 0.8474 - val_loss: 0.0871 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99410\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 92s 654us/step - loss: 0.3059 - acc: 0.8480 - val_loss: 0.1026 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99410\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 96s 688us/step - loss: 0.3025 - acc: 0.8496 - val_loss: 0.0739 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99410\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 94s 668us/step - loss: 0.3017 - acc: 0.8508 - val_loss: 0.1090 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99410 to 0.99527, saving model to results/cnn2/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 90s 641us/step - loss: 0.3011 - acc: 0.8502 - val_loss: 0.0754 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99527\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 86s 615us/step - loss: 0.3008 - acc: 0.8501 - val_loss: 0.0835 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99527\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 96s 687us/step - loss: 0.3005 - acc: 0.8512 - val_loss: 0.0893 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99527\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 99s 704us/step - loss: 0.3029 - acc: 0.8506 - val_loss: 0.0723 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99527\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 100s 710us/step - loss: 0.3015 - acc: 0.8506 - val_loss: 0.1036 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99527\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 105s 749us/step - loss: 0.2990 - acc: 0.8517 - val_loss: 0.0771 - val_acc: 0.9908TA: 15s - loss: 0.2989 - - E - ETA: 2s - loss: 0.2991 - ETA: 1s - loss:\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99527\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 103s 733us/step - loss: 0.2979 - acc: 0.8522 - val_loss: 0.0703 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.99527 to 0.99578, saving model to results/cnn2/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 107s 761us/step - loss: 0.2961 - acc: 0.8530 - val_loss: 0.0783 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99578\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 113s 804us/step - loss: 0.2960 - acc: 0.8533 - val_loss: 0.0741 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99578\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 111s 793us/step - loss: 0.2940 - acc: 0.8539 - val_loss: 0.1171 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99578\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 117s 837us/step - loss: 0.2941 - acc: 0.8537 - val_loss: 0.0786 - val_acc: 0.9930 0. - ETA: 9s  - ETA: 0s - loss: 0.294\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99578\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 112s 799us/step - loss: 0.2941 - acc: 0.8540 - val_loss: 0.1959 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99578\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 109s 775us/step - loss: 0.2921 - acc: 0.8548 - val_loss: 0.0798 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99578\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 108s 768us/step - loss: 0.2907 - acc: 0.8552 - val_loss: 0.0859 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99578\n"
=======
      "140272/140272 [==============================] - 117s 832us/step - loss: 0.4378 - acc: 0.7735 - val_loss: 0.1453 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93045, saving model to results/cnn-gru3results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 113s 809us/step - loss: 0.3876 - acc: 0.8123 - val_loss: 0.1070 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93045 to 0.99518, saving model to results/cnn-gru3results/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 114s 811us/step - loss: 0.3477 - acc: 0.8440 - val_loss: 0.1052 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99518\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 114s 810us/step - loss: 0.3423 - acc: 0.8471 - val_loss: 0.1296 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99518\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 121s 863us/step - loss: 0.3395 - acc: 0.8490 - val_loss: 0.1053 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99518\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 122s 868us/step - loss: 0.3371 - acc: 0.8501 - val_loss: 0.1444 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99518\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 120s 852us/step - loss: 0.3332 - acc: 0.8518 - val_loss: 0.1175 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.99518 to 0.99584, saving model to results/cnn-gru3results/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 121s 860us/step - loss: 0.3330 - acc: 0.8526 - val_loss: 0.1290 - val_acc: 0.9938: 0.3329 - \n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99584\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 131s 931us/step - loss: 0.3289 - acc: 0.8556 - val_loss: 0.1145 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99584\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 121s 866us/step - loss: 0.3145 - acc: 0.8629 - val_loss: 0.0749 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99584\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 118s 838us/step - loss: 0.2831 - acc: 0.8672 - val_loss: 0.1149 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99584\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 126s 901us/step - loss: 0.2794 - acc: 0.8687 - val_loss: 0.0917 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99584\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 125s 892us/step - loss: 0.2772 - acc: 0.8703 - val_loss: 0.0747 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99584\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 121s 864us/step - loss: 0.2860 - acc: 0.8706 - val_loss: 0.0739 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99584\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 123s 879us/step - loss: 0.2723 - acc: 0.8719 - val_loss: 0.0676 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99584\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 119s 847us/step - loss: 0.2730 - acc: 0.8709 - val_loss: 0.0628 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99584\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 115s 823us/step - loss: 0.2699 - acc: 0.8724 - val_loss: 0.0715 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99584\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 117s 835us/step - loss: 0.2679 - acc: 0.8731 - val_loss: 0.0660 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99584\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 122s 872us/step - loss: 0.2660 - acc: 0.8732 - val_loss: 0.0647 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99584\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 129s 917us/step - loss: 0.2659 - acc: 0.8733 - val_loss: 0.0626 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99584\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 133s 950us/step - loss: 0.2643 - acc: 0.8742 - val_loss: 0.0693 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99584\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 137s 977us/step - loss: 0.2636 - acc: 0.8740 - val_loss: 0.0710 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99584\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 134s 954us/step - loss: 0.2625 - acc: 0.8744 - val_loss: 0.0668 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99584\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 130s 928us/step - loss: 0.2626 - acc: 0.8747 - val_loss: 0.0672 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99584\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 124s 885us/step - loss: 0.2615 - acc: 0.8749 - val_loss: 0.0631 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99584\n"
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
     ]
    }
   ],
   "source": [
    "#CNN2\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import GRU, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
<<<<<<< HEAD
=======
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
<<<<<<< HEAD
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn2/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn2/cnn_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:67: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:84: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 234s 2ms/step - loss: 0.4253 - acc: 0.7809 - val_loss: 0.2021 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96230, saving model to results/cnn3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 240s 2ms/step - loss: 0.3585 - acc: 0.8375 - val_loss: 0.1555 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96230 to 0.99053, saving model to results/cnn3/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 240s 2ms/step - loss: 0.3406 - acc: 0.8443 - val_loss: 0.2694 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.99053 to 0.99356, saving model to results/cnn3/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 244s 2ms/step - loss: 0.3101 - acc: 0.8458 - val_loss: 0.0978 - val_acc: 0.9913oss: 0.3 - ETA: 1s - loss:\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99356\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 257s 2ms/step - loss: 0.3058 - acc: 0.8477 - val_loss: 0.0982 - val_acc: 0.9898058 - - ETA\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99356\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 260s 2ms/step - loss: 0.3028 - acc: 0.8482 - val_loss: 0.0726 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99356\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 248s 2ms/step - loss: 0.3094 - acc: 0.8488 - val_loss: 0.1430 - val_acc: 0.9909 1s\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99356\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 257s 2ms/step - loss: 0.3089 - acc: 0.8490 - val_loss: 0.0963 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99356\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 278s 2ms/step - loss: 0.2995 - acc: 0.8497 - val_loss: 0.0794 - val_acc: 0.9932- los\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99356\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 303s 2ms/step - loss: 0.2951 - acc: 0.8513 - val_loss: 0.0718 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99356 to 0.99444, saving model to results/cnn3/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 286s 2ms/step - loss: 0.2942 - acc: 0.8515 - val_loss: 0.0702 - val_acc: 0.9948A: 0s - loss: 0.2943 - ac\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99444 to 0.99475, saving model to results/cnn3/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 300s 2ms/step - loss: 0.2919 - acc: 0.8522 - val_loss: 0.0825 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99475\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 287s 2ms/step - loss: 0.2931 - acc: 0.8529 - val_loss: 0.0730 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99475\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 217s 2ms/step - loss: 0.2904 - acc: 0.8542 - val_loss: 0.0890 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99475\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 217s 2ms/step - loss: 0.2891 - acc: 0.8545 - val_loss: 0.0786 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99475\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 222s 2ms/step - loss: 0.2865 - acc: 0.8571 - val_loss: 0.0839 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99475\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 226s 2ms/step - loss: 0.2840 - acc: 0.8591 - val_loss: 0.0702 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99475\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 266s 2ms/step - loss: 0.2841 - acc: 0.8595 - val_loss: 0.0725 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99475\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 331s 2ms/step - loss: 0.2830 - acc: 0.8607 - val_loss: 0.0701 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99475\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 354s 3ms/step - loss: 0.2819 - acc: 0.8616 - val_loss: 0.0659 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.99475 to 0.99478, saving model to results/cnn3/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 354s 3ms/step - loss: 0.2818 - acc: 0.8622 - val_loss: 0.0758 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99478\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 343s 2ms/step - loss: 0.2818 - acc: 0.8612 - val_loss: 0.0705 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99478\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 346s 2ms/step - loss: 0.2799 - acc: 0.8634 - val_loss: 0.0606 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.99478 to 0.99527, saving model to results/cnn3/checkpoint-23.hdf5\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 350s 2ms/step - loss: 0.2784 - acc: 0.8635 - val_loss: 0.0727 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99527\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 348s 2ms/step - loss: 0.2795 - acc: 0.8631 - val_loss: 0.0680 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99527\n"
     ]
    }
   ],
   "source": [
    "#CNN3\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "\n",
    "lstm_output_size = 128\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn3/cnntrainanalysis3.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn3/cnn_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:65: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:78: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 151s 1ms/step - loss: 0.4929 - acc: 0.7191 - val_loss: 0.1791 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85283, saving model to results/cnn-gru1results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 163s 1ms/step - loss: 0.4397 - acc: 0.7645 - val_loss: 0.1258 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85283 to 0.98845, saving model to results/cnn-gru1results/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 202s 1ms/step - loss: 0.4247 - acc: 0.7841 - val_loss: 0.1303 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98845\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 220s 2ms/step - loss: 0.4156 - acc: 0.7933 - val_loss: 0.1562 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98845\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 262s 2ms/step - loss: 0.4118 - acc: 0.7938 - val_loss: 0.1286 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98845\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 306s 2ms/step - loss: 0.4100 - acc: 0.7955 - val_loss: 0.1536 - val_acc: 0.9646\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98845\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 322s 2ms/step - loss: 0.4100 - acc: 0.7962 - val_loss: 0.1459 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98845\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 355s 3ms/step - loss: 0.4048 - acc: 0.7984 - val_loss: 0.1296 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98845\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 380s 3ms/step - loss: 0.4017 - acc: 0.7997 - val_loss: 0.1541 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98845\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 404s 3ms/step - loss: 0.4000 - acc: 0.8004 - val_loss: 0.1444 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98845\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 438s 3ms/step - loss: 0.4005 - acc: 0.7996 - val_loss: 0.1315 - val_acc: 0.9645ss: 0.4006 - acc: 0\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98845\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 474s 3ms/step - loss: 0.3988 - acc: 0.8008 - val_loss: 0.1371 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98845\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 502s 4ms/step - loss: 0.3972 - acc: 0.8019 - val_loss: 0.1573 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98845\n",
      "Epoch 14/25\n",
      " 47392/140272 [=========>....................] - ETA: 5:43 - loss: 0.3966 - acc: 0.8023"
     ]
    }
   ],
   "source": [
    "#CNN-gru1\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import GRU, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru1results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru1results/cnntrainanalysis1.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru1results/cnn_model.hdf5\")\n",
    "\n",
    "'''\n",
    "\n",
    "cnn.load_weights(\"results/cnn-gru1results/checkpoint-947.hdf5\")\n",
    "\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "y_pred = cnn.predict_classes(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "np.savetxt('res/expected1.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicted1.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:65: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:67: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 204s 1ms/step - loss: 0.4695 - acc: 0.7460 - val_loss: 0.1360 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95178, saving model to results/cnn-gru2results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 284s 2ms/step - loss: 0.4243 - acc: 0.7825 - val_loss: 0.1605 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95178 to 0.95412, saving model to results/cnn-gru2results/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 432s 3ms/step - loss: 0.4170 - acc: 0.7894 - val_loss: 0.1461 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95412\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 522s 4ms/step - loss: 0.4074 - acc: 0.7956 - val_loss: 0.1441 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95412 to 0.97773, saving model to results/cnn-gru2results/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 606s 4ms/step - loss: 0.4042 - acc: 0.7984 - val_loss: 0.1379 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97773\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 646s 5ms/step - loss: 0.4028 - acc: 0.7988 - val_loss: 0.1427 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97773\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 710s 5ms/step - loss: 0.4048 - acc: 0.7984 - val_loss: 0.1450 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97773\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 805s 6ms/step - loss: 0.4043 - acc: 0.7979 - val_loss: 0.1531 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.97773\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 892s 6ms/step - loss: 0.4028 - acc: 0.7983 - val_loss: 0.1386 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97773\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 1004s 7ms/step - loss: 0.3965 - acc: 0.8019 - val_loss: 0.1274 - val_acc: 0.9638\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97773\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 1106s 8ms/step - loss: 0.3952 - acc: 0.8023 - val_loss: 0.1520 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97773\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 1194s 9ms/step - loss: 0.3962 - acc: 0.8003 - val_loss: 0.1523 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97773\n",
      "Epoch 13/25\n",
      "129408/140272 [==========================>...] - ETA: 1:35 - loss: 0.3955 - acc: 0.8029"
     ]
    }
   ],
   "source": [
    "#CNN-GRU2\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import GRU, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru2results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru2results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru2results/cnn_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:32: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:86: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 166s 1ms/step - loss: 0.4380 - acc: 0.7738 - val_loss: 0.1461 - val_acc: 0.9303\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93031, saving model to results/cnn-gru3results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 219s 2ms/step - loss: 0.3797 - acc: 0.8185 - val_loss: 0.1139 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93031 to 0.99481, saving model to results/cnn-gru3results/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 291s 2ms/step - loss: 0.3492 - acc: 0.8426 - val_loss: 0.1185 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99481\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 312s 2ms/step - loss: 0.3434 - acc: 0.8469 - val_loss: 0.1348 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99481\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 345s 2ms/step - loss: 0.3394 - acc: 0.8489 - val_loss: 0.1057 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99481\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 418s 3ms/step - loss: 0.3383 - acc: 0.8488 - val_loss: 0.1315 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99481\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 576s 4ms/step - loss: 0.3331 - acc: 0.8518 - val_loss: 0.1153 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99481\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 673s 5ms/step - loss: 0.3336 - acc: 0.8512 - val_loss: 0.1308 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99481\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 732s 5ms/step - loss: 0.3258 - acc: 0.8585 - val_loss: 0.1107 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99481 to 0.99547, saving model to results/cnn-gru3results/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 617s 4ms/step - loss: 0.3199 - acc: 0.8638 - val_loss: 0.1234 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99547\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 629s 4ms/step - loss: 0.3184 - acc: 0.8648 - val_loss: 0.1324 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99547\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 696s 5ms/step - loss: 0.3156 - acc: 0.8668 - val_loss: 0.1163 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99547\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 726s 5ms/step - loss: 0.3112 - acc: 0.8677 - val_loss: 0.1126 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99547\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 793s 6ms/step - loss: 0.2803 - acc: 0.8704 - val_loss: 0.1091 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99547\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 849s 6ms/step - loss: 0.2772 - acc: 0.8716 - val_loss: 0.0740 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99547\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 901s 6ms/step - loss: 0.2750 - acc: 0.8721 - val_loss: 0.0798 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99547\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 963s 7ms/step - loss: 0.2726 - acc: 0.8725 - val_loss: 0.0703 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99547\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 994s 7ms/step - loss: 0.2708 - acc: 0.8737 - val_loss: 0.1039 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99547\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 1068s 8ms/step - loss: 0.2704 - acc: 0.8736 - val_loss: 0.0877 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99547\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 1131s 8ms/step - loss: 0.2668 - acc: 0.8750 - val_loss: 0.0595 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99547\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 1162s 8ms/step - loss: 0.2666 - acc: 0.8747 - val_loss: 0.0694 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99547\n",
      "Epoch 22/25\n",
      "140256/140272 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.8752"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-8dac88d6ed18>\", line 86, in <module>\n",
      "    cnn.fit(X_train, y_train, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1039, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 212, in fit_loop\n",
      "    verbose=0)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 392, in test_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2715, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2675, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1458, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\inspect.py\", line 1450, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 185, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\tokenize.py\", line 452, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#CNN-GRU3\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import GRU, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gru_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(GRU(gru_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru3results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru3results/cnntrainanalysis3.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru3results/cnn_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:32: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:67: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 197s 1ms/step - loss: 0.4848 - acc: 0.7162 - val_loss: 0.1946 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96909, saving model to results/cnn-lstm1results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 217s 2ms/step - loss: 0.4487 - acc: 0.7534 - val_loss: 0.1370 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96909 to 0.99818, saving model to results/cnn-lstm1results/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 313s 2ms/step - loss: 0.4272 - acc: 0.7739 - val_loss: 0.1629 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99818\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 413s 3ms/step - loss: 0.4175 - acc: 0.7833 - val_loss: 0.1482 - val_acc: 0.9867: 2s - \n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99818\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 425s 3ms/step - loss: 0.4119 - acc: 0.7929 - val_loss: 0.1506 - val_acc: 0.9368 -\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99818\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 485s 3ms/step - loss: 0.4070 - acc: 0.7976 - val_loss: 0.1475 - val_acc: 0.9564\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99818\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 561s 4ms/step - loss: 0.4059 - acc: 0.7976 - val_loss: 0.1380 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99818\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 629s 4ms/step - loss: 0.4004 - acc: 0.7998 - val_loss: 0.1512 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99818\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 701s 5ms/step - loss: 0.3984 - acc: 0.8010 - val_loss: 0.1417 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99818\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 775s 6ms/step - loss: 0.3986 - acc: 0.8017 - val_loss: 0.1452 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99818\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 874s 6ms/step - loss: 0.3866 - acc: 0.8110 - val_loss: 0.1357 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99818\n",
      "Epoch 12/25\n",
      "132544/140272 [===========================>..] - ETA: 52s - loss: 0.3602 - acc: 0.8299"
     ]
    }
   ],
   "source": [
    "#CNN-LSTM1\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "lstm_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(LSTM(lstm_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-lstm1results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-lstm1results/cnntrainanalysis1.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-lstm1results/cnn_model.hdf5\")\n",
    "\n",
    "'''\n",
    "\n",
    "cnn.load_weights(\"results/cnn-lstm1results/checkpoint-947.hdf5\")\n",
    "\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "\n",
    "y_pred = cnn.predict_classes(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "np.savetxt('res/expected1.txt', y_test, fmt='%01d')\n",
    "np.savetxt('res/predicted1.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:32: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:67: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:80: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 192s 1ms/step - loss: 0.4805 - acc: 0.7151 - val_loss: 0.1798 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98714, saving model to results/cnn-lstm2results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 248s 2ms/step - loss: 0.4255 - acc: 0.7783 - val_loss: 0.1709 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.98714\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 359s 3ms/step - loss: 0.4126 - acc: 0.7884 - val_loss: 0.1413 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98714\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 421s 3ms/step - loss: 0.4130 - acc: 0.7914 - val_loss: 0.1476 - val_acc: 0.9291:  - ETA: 4:39 - loss: 0.4226  - ETA: 4:38 - - ET - ETA: 4:24 - loss: 0 - ETA: 4:23 - loss: 0.4219 - acc: - ETA: 4:22 - - ETA: 4:04 - loss: 0.4206 - acc - ETA: 4:03 - loss: 0.4208 - ac - ETA: 4:02 - loss: 0.4206 - acc: 0.78 - ETA: 4:02 - loss: 0.4207 - acc: 0.78 -  - ETA: 3:52 - loss: 0.4192 - acc: 0.78 - ETA: 3:52 - loss: 0.4191 - acc: 0.7 - ETA: 3:52 - loss: 0.4190 - acc: - ETA: 3:51 - lo - ETA: 3:49 - loss: 0.4186 - acc: 0 - ETA: 3:48 - loss: 0.4185  -  - ETA: 3:34 - loss: 0.41 - ETA: 3:32 - loss: 0.4184 - acc: 0.788 - ETA: 3:32 - loss: 0.4185  - ETA: 3:31 - loss: 0.418 - ETA: 3:27 - loss: 0.4180 - acc:  - ETA: 3:26 - los - ETA: 3:24 - loss: 0.4183 - acc: 0.78 - ETA: 3:24 - loss: 0.41 - ETA: 3:23 - loss: 0.4181 - acc: 0.788 - ETA: 3:23 - loss: 0.4181 - acc:   - ETA: 3:19 - loss: - ETA: 3:17 - loss: 0.4178 - acc: 0.78 - ETA: 3:17 - loss: 0.4178 - acc: 0. - ETA: 3:16 - loss: 0.4177 - acc: 0.78 - ETA: 3:16 - loss: 0.41 - ETA: 3:15 - los - ETA: 3:13 - loss: 0.4175 - ETA: 3:12 - loss: 0.4175 - acc: 0.78 - ETA: 3:11 - loss: 0.4175 - acc: 0 - ETA: 3:11 - loss: 0.4177 - - ETA: 3:06 - loss: 0.4178 - - ETA: 3:02 - loss: 0. - ETA: 3:00 - loss: 0.4175 - acc: - ETA: 2:59 - loss: 0.4175 - acc: - ETA: 2:59 - loss: 0.4176 - acc:  - ETA: 2:58 - loss: 0.4177 - acc: 0.789 -  - ETA: - ETA: 2:52 - loss: 0.4167 - acc: 0 - ETA: 2:52 - loss: 0.4166 - a - ETA: 2:51 - loss: 0.4166 - - - ETA: 2:46 - loss: 0.4161 - acc - ETA: 2:46 - loss: 0.4160 - acc - ETA: 2:45 - lo - ETA: 2:29 - loss: 0.4151 -  - ETA: 2:28 - loss: 0.4150 - acc:  - ETA: 2:24 - loss: 0.4 - ETA: 2:23 -  - ETA: 2:20 - loss: 0.4155 - acc: 0.7 - ETA: 2:20 - loss: 0.4156 - acc: 0. - ETA: 2:20 - loss: 0.4154 - acc:  - ETA: 2:19 - loss: 0.4153 - acc: 0 - ETA: 2:19 - loss: 0.4153 - ac - ETA: 2 - ETA:  - - ETA: 2:06 - loss: 0.4150 - ac - ETA: 1:59 - loss: 0.4140 - acc: 0.790 - ETA: 1:58 - loss - ETA: 1:57 - loss: 0.4140 - - ETA: 1:45 - loss: 0.4142 - acc: 0.790 - ETA: 1:45 - loss: 0.4142 - ETA: 1:44 - loss: 0.4139 - ac - ETA: 1:43 - loss: 0.4139 - acc: 0.790 - ETA: 1:43 - loss: 0.4139 -  - ETA: 1:42 - loss: 0.4142 - acc: 0.79 - ETA - ETA: 1: - ETA: 1:21 - loss: 0.4146 - acc - ETA: 1:20 - loss: 0.4147 - acc: 0.7 - ETA: 1:20 - loss: 0. - - ETA: 1:11 - l\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98714\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 493s 4ms/step - loss: 0.4126 - acc: 0.7936 - val_loss: 0.1468 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98714\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 580s 4ms/step - loss: 0.4090 - acc: 0.7963 - val_loss: 0.2170 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98714\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 681s 5ms/step - loss: 0.4110 - acc: 0.7906 - val_loss: 0.1705 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98714\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 774s 6ms/step - loss: 0.4033 - acc: 0.7969 - val_loss: 0.1413 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98714\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 851s 6ms/step - loss: 0.4010 - acc: 0.7986 - val_loss: 0.1313 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98714\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 992s 7ms/step - loss: 0.3999 - acc: 0.7997 - val_loss: 0.1390 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98714\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 1106s 8ms/step - loss: 0.3965 - acc: 0.8019 - val_loss: 0.1577 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98714\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 1209s 9ms/step - loss: 0.3976 - acc: 0.8001 - val_loss: 0.1428 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98714\n",
      "Epoch 13/25\n",
      "138560/140272 [============================>.] - ETA: 15s - loss: 0.3953 - acc: 0.8016"
     ]
    }
   ],
   "source": [
    "#CNN-lstm2\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "lstm_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(LSTM(lstm_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-lstm2results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-lstm2results/cnntrainanalysis2.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-lstm2results/cnn_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:32: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(43, 1), padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "C:\\Users\\Vamsi\\AppData\\Local\\conda\\conda\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:86: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 238s 2ms/step - loss: 0.4378 - acc: 0.7751 - val_loss: 0.1651 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94882, saving model to results/cnn-lstm3results/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 323s 2ms/step - loss: 0.4090 - acc: 0.7957 - val_loss: 0.1363 - val_acc: 0.9603\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94882 to 0.96031, saving model to results/cnn-lstm3results/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 440s 3ms/step - loss: 0.3967 - acc: 0.8034 - val_loss: 0.1498 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.96031 to 0.97821, saving model to results/cnn-lstm3results/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 587s 4ms/step - loss: 0.3625 - acc: 0.8335 - val_loss: 0.1499 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97821\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 701s 5ms/step - loss: 0.3498 - acc: 0.8433 - val_loss: 0.1266 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97821 to 0.98902, saving model to results/cnn-lstm3results/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 838s 6ms/step - loss: 0.3437 - acc: 0.8473 - val_loss: 0.1328 - val_acc: 0.9776 9:43 - loss: 0.34 - ETA: 9:41 - loss: 0.3454 - a - ETA: 9:40 - loss - ETA: 9:37 -  - ETA: - ETA: 9:21 - - E - ETA: 9:06 - loss: 0.3431 - acc - ETA: 9: - ETA: 9:00 - loss: 0.3433 - a - ETA: 7:24 - loss: 0.3423 - - ETA:  - ETA: 7:17 - loss:  - ETA: 7:09 - loss: 0.3432 - ETA: 7:06 - loss: 0.3431 -  - ETA: 7:05 - loss: 0.3429 - acc: 0. - ETA: 7:04 - l - ETA: 7:00 - loss:  - ETA: 6: - ETA: 6:46 - loss: 0.3436 - acc: - ETA: 6:45 - loss: 0.3436 - acc: 0.84 - ETA: 6:45 - loss: 0.3435 - acc: 0.848 - ETA: 6: - ETA: 6:40  - ETA: 6:36 - loss: 0.3439 - acc:  - ETA: 6:35 - loss:  - ETA: 6:3 - ETA: 6:27 - loss: 0.3443 - acc - ETA: 6:25 - loss: 0.3443 - acc: 0.84 - ETA: 6:25 - loss: 0.3442 - acc: 0.847 - ETA: 6:25 - l - ETA: 6:21 - loss: 0.3443 -  - ETA: 6:19 - loss: 0.3444 - a - ETA: 6:18 - loss: 0.3445 - acc: 0 - ETA: 6:17 - loss: 0.3447 - acc: - ETA: 6:10 - loss:  - ETA: 6:06 - loss: 0.3439 - acc: 0.84 - ETA: 6:06 -  - ETA: 5:55 - loss: 0.3441 - acc: 0.847 - ETA: 5:55 - loss: 0.3441 - acc:  - ETA: 5:54 - loss: 0.3442 - acc - ETA: 5:53 - loss: 0.3441 - acc: 0. - ETA: 5:52 - loss: 0.3441 - acc: 0 - ETA: 5:51 - l - ETA: 5:48 - loss: 0.3442 - ac - ETA: 5:46 - loss: 0.3443 - - ETA: 5:44 - loss: 0.3443 - acc: - ETA: 5:43 - loss: 0.3446 - acc: 0.84 - ETA: 5:43 - loss: 0.3446 - acc: 0.847 - - ETA: 5:36 - loss: 0.3446 - acc: 0 - ETA: 5:29 - loss: 0.3441 - acc: 0.8 - ETA: 5:29 - loss: 0.3442 - acc:  - ETA: 5:28 - loss: 0.3442  - ETA: 5:26 - loss: 0.3444 -  - ETA: 5:24 - loss:  - ETA: 5:14 - loss: 0.3445 - acc:  - ETA: 5:14 - loss:  - ETA: 5:10  - ETA: 5:06 - loss: 0.3443 - - ETA: 5:04 - loss: 0.344 - ETA: 5:01 - loss: 0.3443 - acc: 0.847 - ETA: 5:01 - loss: - ETA: 4:58 - loss: 0.3 - ETA: 4:55 - loss: 0.3438 - ac - ETA: 4:54 - ETA: 4:50 - loss: 0.3439 - acc - ETA: 4:48 - loss: 0.3441 - acc: 0. - ETA: 4:48 - loss: 0.3441 - acc: 0.84 - ETA: 4:47 - loss: 0.3441 - - ETA: 4:46 - loss: 0.3443 - acc - ETA: 4:45 - l - ETA: 4:40 - loss: 0.3447 - acc: 0.847 - ETA: 4: - ETA: 4:35 - loss:  - ETA: 4:25 - lo - ETA: 4:21 - loss:  - ETA: 4:18 - loss: 0.344 - ETA:  - ETA: 4:10 - loss: 0.3440 - acc: 0 - ETA: 4:09 - loss: 0.3443 - acc: 0.848 - ETA: 4:09 -  - ETA: 4:05 - loss: 0.3441  - ETA: 4:03 - loss: 0.3442 - acc: 0 - ETA: 4:02  - ETA: 3:58 - loss: - ETA: 3:54 - loss: 0.3446 - ac - ETA: 3:53 - loss: 0.3445 - acc: 0.84 - ETA: 3:52 - loss: 0.3445 - acc: 0 - ETA: 3: - ETA: 3:46 - loss: 0.3445 - acc: 0 - ETA: 3:46 - loss: 0.3445 - acc:  - ETA: 3:45 - loss: 0.3445 - acc: 0.847 - ETA: 3:44 - loss: 0.3445 - acc - ETA: 3:43 - loss: 0.3445 - acc:  - ETA: 3:42 - loss: 0.3445 - acc: 0.8 - ETA: 3:42 - loss: 0.34 - ETA: 3:39 - loss: 0.3446 - acc:  - ETA: 3:38 - loss: 0.3447 - acc: 0.847 - ETA: 3:38 - loss: 0.3447 - acc: 0.84 - ETA: 3:37 - loss: 0.3447 - acc: 0.8 - ETA: 3:37 - loss: 0.3447 -  - ETA: 3:35 - loss: 0.3447 - acc: 0.847 - ETA: 3:35 - loss: 0.3447 - acc: 0. - ETA: 3:34 - loss: 0.3447 - acc: 0 - ETA: 3:33 - loss: 0.3446 - acc: 0.8 - ETA: 3:3 - ETA: 3:28 - loss: 0.3447 - acc: 0.8 - ETA: 3:27 - loss: 0.3447 - acc - ETA: 3:26 - loss: 0.3447 - acc: 0.8 - ETA: 3:26 - l - ETA: 3:21 - loss: 0.3447 - acc:  - ETA: 3:20 - loss: 0.3448  - ETA: 3:18 - loss: 0.3449 - ac - ETA: 3:17 - loss: 0.3449 - acc: 0 - ETA: 3:16 - loss: 0.3449 - acc:  - ETA: 3:15 - loss: 0.3447 - acc - ETA: 3:14 - loss: 0.3445 - acc: 0.84 - ETA: 3:13 - loss: 0.3445 - acc: 0.84 - ETA: 3:13 - loss:  - ETA: 3:10 - loss: 0.3446 - acc: 0.8 - ETA: 3:09 - loss: 0.3446 - acc - ETA: 3 - ETA: 2:56 - loss: 0.3449 - acc: 0.84 - ETA: 2:55 - loss: 0.3449 - acc: 0.847 - ETA: 2:55 - loss: 0.3449 - - ETA: 2:53 - loss: 0.3449 - acc - ETA: 2:52 - loss: 0.3449 - acc: 0.84 - ETA: 2:51 - loss: 0 - ET - ETA: 2:43 - loss: 0.3446 - ac - ET - ETA: 2:35 - loss: 0.3444 - acc: 0 - ETA: 2:34 - loss: 0.3444 - acc: 0. - ETA: 2:34 - loss: 0.3444 - acc: 0.8 - ETA: 2:33 - loss: 0.344 - ETA: 2:24 - loss: 0.3444 - acc: 0.847 - ETA: 2:23 - loss: 0.3444 - acc:  - ETA: 2:22 - loss: 0.3443 - - ETA: 2:20 - loss: 0.3444 - acc:  - ETA: 2:19 - loss: 0.3444 - acc: 0 - ETA: 2:18 - loss: 0.3444 - acc: 0 - ETA: 2:18 - loss: 0. - ETA: 2:15  - ETA: 2:10 - loss: 0.3443 - acc: 0 - ETA: 2:09 - loss: 0.3 - ETA: 2:06 - loss: 0.3443 - ETA: 2:04 - loss: 0.3444 - a - ETA: - ETA: 1:49 - loss: 0.3444 - acc: - ETA: 1:48 - loss: 0.3445 - a - ETA: 1:46 - loss: 0.3445 - acc: 0.847 - ETA: 1:46 - loss: 0.3445 - acc: 0 - ETA: 1:45 - loss: 0.3445 - ETA: 1:36 - loss: 0.3442   - - ETA: 24s - lo - E - ET - ETA: 2s - loss: 0.3437 -\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98902\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 811s 6ms/step - loss: 0.3420 - acc: 0.8476 - val_loss: 0.1040 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.98902 to 0.99424, saving model to results/cnn-lstm3results/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 830s 6ms/step - loss: 0.3371 - acc: 0.8499 - val_loss: 0.1269 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99424\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 952s 7ms/step - loss: 0.3067 - acc: 0.8528 - val_loss: 0.0959 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99424\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 1074s 8ms/step - loss: 0.2915 - acc: 0.8603 - val_loss: 0.0781 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99424\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 1187s 8ms/step - loss: 0.2826 - acc: 0.8665 - val_loss: 0.0694 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99424\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 1309s 9ms/step - loss: 0.2768 - acc: 0.8702 - val_loss: 0.0810 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.99424 to 0.99601, saving model to results/cnn-lstm3results/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 1454s 10ms/step - loss: 0.2736 - acc: 0.8724 - val_loss: 0.2907 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99601\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 1580s 11ms/step - loss: 0.2959 - acc: 0.8629 - val_loss: 0.1391 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99601\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 1714s 12ms/step - loss: 0.3336 - acc: 0.8545 - val_loss: 0.1230 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99601\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 1859s 13ms/step - loss: 0.3331 - acc: 0.8537 - val_loss: 0.1341 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99601\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 1997s 14ms/step - loss: 0.3282 - acc: 0.8565 - val_loss: 0.1378 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99601\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 2073s 15ms/step - loss: 0.3118 - acc: 0.8582 - val_loss: 0.1059 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99601\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 2304s 16ms/step - loss: 0.2847 - acc: 0.8652 - val_loss: 0.1226 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99601\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 2360s 17ms/step - loss: 0.2808 - acc: 0.8679 - val_loss: 0.0857 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99601\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 2435s 17ms/step - loss: 0.2893 - acc: 0.8628 - val_loss: 0.1310 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99601\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 2844s 20ms/step - loss: 0.2842 - acc: 0.8654 - val_loss: 0.0919 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99601\n",
      "Epoch 23/25\n",
      " 60416/140272 [===========>..................] - ETA: 29:52 - loss: 0.2783 - acc: 0.8691"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lstm_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(43, 1)))\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(LSTM(lstm_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-lstm3results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-lstm3results/cnntrainanalysis3.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-lstm3results/cnn_model.hdf5\")\n"
=======
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn-gru3results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn-gru3results/cnntrainanalysis3.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=25,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn-gru3results/cnn_model.hdf5\")\n"
>>>>>>> 07a226e8410d806621f92299d663b323e18cefac
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
