{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 9s 63us/step - loss: 0.4624 - acc: 0.7304 - val_loss: 0.1722 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.46240, saving model to results/dnn1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 9s 64us/step - loss: 0.4407 - acc: 0.7605 - val_loss: 0.1258 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00002: loss improved from 0.46240 to 0.44067, saving model to results/dnn1/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 8s 59us/step - loss: 0.4231 - acc: 0.7878 - val_loss: 0.1250 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00003: loss improved from 0.44067 to 0.42311, saving model to results/dnn1/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 9s 64us/step - loss: 0.4074 - acc: 0.8057 - val_loss: 0.1627 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00004: loss improved from 0.42311 to 0.40738, saving model to results/dnn1/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 9s 61us/step - loss: 0.3942 - acc: 0.8157 - val_loss: 0.1499 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00005: loss improved from 0.40738 to 0.39420, saving model to results/dnn1/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 9s 63us/step - loss: 0.3848 - acc: 0.8219 - val_loss: 0.1274 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00006: loss improved from 0.39420 to 0.38479, saving model to results/dnn1/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3777 - acc: 0.8254 - val_loss: 0.1421 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00007: loss improved from 0.38479 to 0.37774, saving model to results/dnn1/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3729 - acc: 0.8267 - val_loss: 0.1480 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00008: loss improved from 0.37774 to 0.37288, saving model to results/dnn1/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 8s 59us/step - loss: 0.3685 - acc: 0.8300 - val_loss: 0.1348 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00009: loss improved from 0.37288 to 0.36849, saving model to results/dnn1/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3663 - acc: 0.8314 - val_loss: 0.1463 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00010: loss improved from 0.36849 to 0.36627, saving model to results/dnn1/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3633 - acc: 0.8331 - val_loss: 0.1068 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00011: loss improved from 0.36627 to 0.36332, saving model to results/dnn1/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 9s 64us/step - loss: 0.3614 - acc: 0.8342 - val_loss: 0.1461 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00012: loss improved from 0.36332 to 0.36139, saving model to results/dnn1/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.3604 - acc: 0.8347 - val_loss: 0.0910 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00013: loss improved from 0.36139 to 0.36043, saving model to results/dnn1/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 9s 67us/step - loss: 0.3591 - acc: 0.8355 - val_loss: 0.1362 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00014: loss improved from 0.36043 to 0.35910, saving model to results/dnn1/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 9s 65us/step - loss: 0.3582 - acc: 0.8359 - val_loss: 0.1233 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00015: loss improved from 0.35910 to 0.35823, saving model to results/dnn1/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 9s 63us/step - loss: 0.3583 - acc: 0.8356 - val_loss: 0.1154 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.35823\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3566 - acc: 0.8370 - val_loss: 0.1297 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00017: loss improved from 0.35823 to 0.35664, saving model to results/dnn1/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 8s 57us/step - loss: 0.3565 - acc: 0.8367 - val_loss: 0.1115 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00018: loss improved from 0.35664 to 0.35647, saving model to results/dnn1/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 8s 59us/step - loss: 0.3565 - acc: 0.8365 - val_loss: 0.0995 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.35647\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 8s 55us/step - loss: 0.3553 - acc: 0.8374 - val_loss: 0.1190 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00020: loss improved from 0.35647 to 0.35527, saving model to results/dnn1/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 8s 59us/step - loss: 0.3546 - acc: 0.8386 - val_loss: 0.0876 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00021: loss improved from 0.35527 to 0.35464, saving model to results/dnn1/checkpoint-21.hdf5\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.3553 - acc: 0.8379 - val_loss: 0.0942 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.35464\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 8s 60us/step - loss: 0.3554 - acc: 0.8375 - val_loss: 0.1108 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.35464\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 9s 62us/step - loss: 0.3553 - acc: 0.8384 - val_loss: 0.2004 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.35464\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 8s 58us/step - loss: 0.3546 - acc: 0.8376 - val_loss: 0.1535 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00025: loss improved from 0.35464 to 0.35463, saving model to results/dnn1/checkpoint-25.hdf5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn1/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn1/dnn1layer_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 68s 488us/step - loss: 0.4344 - acc: 0.7665 - val_loss: 0.1423 - val_acc: 0.9657\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.43442, saving model to results/dnn2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 64s 456us/step - loss: 0.3956 - acc: 0.8064 - val_loss: 0.1255 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00002: loss improved from 0.43442 to 0.39559, saving model to results/dnn2/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 65s 466us/step - loss: 0.3758 - acc: 0.8226 - val_loss: 0.1077 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00003: loss improved from 0.39559 to 0.37576, saving model to results/dnn2/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 64s 456us/step - loss: 0.3613 - acc: 0.8314 - val_loss: 0.1647 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00004: loss improved from 0.37576 to 0.36135, saving model to results/dnn2/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 64s 457us/step - loss: 0.3551 - acc: 0.8357 - val_loss: 0.1493 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00005: loss improved from 0.36135 to 0.35506, saving model to results/dnn2/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 64s 456us/step - loss: 0.3529 - acc: 0.8370 - val_loss: 0.1490 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00006: loss improved from 0.35506 to 0.35294, saving model to results/dnn2/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 65s 463us/step - loss: 0.3524 - acc: 0.8374 - val_loss: 0.1462 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00007: loss improved from 0.35294 to 0.35236, saving model to results/dnn2/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 72s 512us/step - loss: 0.3500 - acc: 0.8392 - val_loss: 0.1379 - val_acc: 0.9902 ETA: 4s - loss: 0.3508 - ac - ETA: 4s - ETA: 0s - loss: 0.3501 - acc: 0.83\n",
      "\n",
      "Epoch 00008: loss improved from 0.35236 to 0.35003, saving model to results/dnn2/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 71s 508us/step - loss: 0.3496 - acc: 0.8400 - val_loss: 0.1286 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00009: loss improved from 0.35003 to 0.34957, saving model to results/dnn2/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 68s 487us/step - loss: 0.3482 - acc: 0.8413 - val_loss: 0.1399 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00010: loss improved from 0.34957 to 0.34821, saving model to results/dnn2/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 69s 493us/step - loss: 0.3479 - acc: 0.8413 - val_loss: 0.1208 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00011: loss improved from 0.34821 to 0.34785, saving model to results/dnn2/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 64s 457us/step - loss: 0.3466 - acc: 0.8421 - val_loss: 0.1526 - val_acc: 0.9575\n",
      "\n",
      "Epoch 00012: loss improved from 0.34785 to 0.34663, saving model to results/dnn2/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 66s 470us/step - loss: 0.3495 - acc: 0.8425 - val_loss: 0.1188 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.34663\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 69s 493us/step - loss: 0.3471 - acc: 0.8416 - val_loss: 0.1288 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.34663\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 69s 495us/step - loss: 0.3459 - acc: 0.8425 - val_loss: 0.1115 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00015: loss improved from 0.34663 to 0.34587, saving model to results/dnn2/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 71s 506us/step - loss: 0.3470 - acc: 0.8420 - val_loss: 0.1315 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.34587\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 74s 529us/step - loss: 0.3448 - acc: 0.8436 - val_loss: 0.1262 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00017: loss improved from 0.34587 to 0.34478, saving model to results/dnn2/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 69s 489us/step - loss: 0.3456 - acc: 0.8432 - val_loss: 0.1007 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.34478\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 69s 492us/step - loss: 0.3459 - acc: 0.8424 - val_loss: 0.1192 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.34478\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 71s 504us/step - loss: 0.3453 - acc: 0.8432 - val_loss: 0.1171 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.34478\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 66s 473us/step - loss: 0.3435 - acc: 0.8443 - val_loss: 0.1259 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00021: loss improved from 0.34478 to 0.34348, saving model to results/dnn2/checkpoint-21.hdf5\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 67s 477us/step - loss: 0.3432 - acc: 0.8451 - val_loss: 0.1460 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00022: loss improved from 0.34348 to 0.34319, saving model to results/dnn2/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 65s 466us/step - loss: 0.3441 - acc: 0.8444 - val_loss: 0.1316 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.34319\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 64s 459us/step - loss: 0.3440 - acc: 0.8442 - val_loss: 0.1187 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.34319\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 65s 465us/step - loss: 0.3438 - acc: 0.8443 - val_loss: 0.1469 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.34319\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn2/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn2/dnn2_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 97s 689us/step - loss: 0.4236 - acc: 0.7780 - val_loss: 0.1730 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.42356, saving model to results/dnn3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 95s 676us/step - loss: 0.3966 - acc: 0.8009 - val_loss: 0.1603 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00002: loss improved from 0.42356 to 0.39661, saving model to results/dnn3/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 100s 715us/step - loss: 0.3887 - acc: 0.8092 - val_loss: 0.1304 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00003: loss improved from 0.39661 to 0.38868, saving model to results/dnn3/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 98s 702us/step - loss: 0.3672 - acc: 0.8275 - val_loss: 0.1255 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00004: loss improved from 0.38868 to 0.36719, saving model to results/dnn3/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 95s 680us/step - loss: 0.3568 - acc: 0.8347 - val_loss: 0.1428 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00005: loss improved from 0.36719 to 0.35681, saving model to results/dnn3/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 99s 703us/step - loss: 0.3534 - acc: 0.8369 - val_loss: 0.1438 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00006: loss improved from 0.35681 to 0.35338, saving model to results/dnn3/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 95s 674us/step - loss: 0.3520 - acc: 0.8380 - val_loss: 0.1256 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00007: loss improved from 0.35338 to 0.35196, saving model to results/dnn3/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 102s 730us/step - loss: 0.3487 - acc: 0.8407 - val_loss: 0.1169 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00008: loss improved from 0.35196 to 0.34872, saving model to results/dnn3/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 98s 696us/step - loss: 0.3487 - acc: 0.8401 - val_loss: 0.1338 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.34872\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 96s 681us/step - loss: 0.3493 - acc: 0.8404 - val_loss: 0.1433 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.34872\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 95s 676us/step - loss: 0.3484 - acc: 0.8411 - val_loss: 0.1137 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00011: loss improved from 0.34872 to 0.34840, saving model to results/dnn3/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 97s 690us/step - loss: 0.3471 - acc: 0.8410 - val_loss: 0.1199 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00012: loss improved from 0.34840 to 0.34708, saving model to results/dnn3/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 97s 690us/step - loss: 0.3479 - acc: 0.8408 - val_loss: 0.1212 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.34708\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 98s 695us/step - loss: 0.3470 - acc: 0.8415 - val_loss: 0.1362 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00014: loss improved from 0.34708 to 0.34701, saving model to results/dnn3/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 96s 683us/step - loss: 0.3467 - acc: 0.8418 - val_loss: 0.1338 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00015: loss improved from 0.34701 to 0.34668, saving model to results/dnn3/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 94s 671us/step - loss: 0.3461 - acc: 0.8418 - val_loss: 0.1404 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00016: loss improved from 0.34668 to 0.34611, saving model to results/dnn3/checkpoint-16.hdf5\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 95s 679us/step - loss: 0.3459 - acc: 0.8424 - val_loss: 0.1320 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00017: loss improved from 0.34611 to 0.34589, saving model to results/dnn3/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 98s 696us/step - loss: 0.3459 - acc: 0.8427 - val_loss: 0.1188 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00018: loss improved from 0.34589 to 0.34588, saving model to results/dnn3/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 104s 740us/step - loss: 0.3446 - acc: 0.8436 - val_loss: 0.1230 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00019: loss improved from 0.34588 to 0.34462, saving model to results/dnn3/checkpoint-19.hdf5\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 96s 688us/step - loss: 0.3439 - acc: 0.8446 - val_loss: 0.1220 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00020: loss improved from 0.34462 to 0.34388, saving model to results/dnn3/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 98s 700us/step - loss: 0.3445 - acc: 0.8439 - val_loss: 0.1161 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.34388\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 100s 711us/step - loss: 0.3430 - acc: 0.8453 - val_loss: 0.1327 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00022: loss improved from 0.34388 to 0.34298, saving model to results/dnn3/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 100s 710us/step - loss: 0.3436 - acc: 0.8447 - val_loss: 0.1067 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.34298\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 100s 712us/step - loss: 0.3433 - acc: 0.8443 - val_loss: 0.1334 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.34298\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 100s 716us/step - loss: 0.3444 - acc: 0.8433 - val_loss: 0.1211 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.34298\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn3/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn3/dnn3_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.4241 - acc: 0.7774 - val_loss: 0.1989 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.42407, saving model to results/dnn4/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 109s 779us/step - loss: 0.4000 - acc: 0.7995 - val_loss: 0.1924 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00002: loss improved from 0.42407 to 0.40004, saving model to results/dnn4/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 125s 891us/step - loss: 0.3963 - acc: 0.8020 - val_loss: 0.1355 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00003: loss improved from 0.40004 to 0.39632, saving model to results/dnn4/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 112s 796us/step - loss: 0.3880 - acc: 0.8119 - val_loss: 0.1230 - val_acc: 0.9802: 0.81 - ETA: 0s - loss: 0.3879 - acc: 0.811\n",
      "\n",
      "Epoch 00004: loss improved from 0.39632 to 0.38795, saving model to results/dnn4/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 106s 757us/step - loss: 0.3662 - acc: 0.8263 - val_loss: 0.1167 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00005: loss improved from 0.38795 to 0.36621, saving model to results/dnn4/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 99s 707us/step - loss: 0.3601 - acc: 0.8305 - val_loss: 0.1405 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00006: loss improved from 0.36621 to 0.36012, saving model to results/dnn4/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 100s 712us/step - loss: 0.3552 - acc: 0.8359 - val_loss: 0.1243 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00007: loss improved from 0.36012 to 0.35519, saving model to results/dnn4/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 100s 710us/step - loss: 0.3515 - acc: 0.8383 - val_loss: 0.1351 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00008: loss improved from 0.35519 to 0.35150, saving model to results/dnn4/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 97s 692us/step - loss: 0.3524 - acc: 0.8376 - val_loss: 0.1249 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.35150\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 99s 708us/step - loss: 0.3503 - acc: 0.8396 - val_loss: 0.1496 - val_acc: 0.99507s - lo - ETA: 2\n",
      "\n",
      "Epoch 00010: loss improved from 0.35150 to 0.35025, saving model to results/dnn4/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 97s 689us/step - loss: 0.3498 - acc: 0.8390 - val_loss: 0.1287 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00011: loss improved from 0.35025 to 0.34976, saving model to results/dnn4/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 99s 703us/step - loss: 0.3493 - acc: 0.8400 - val_loss: 0.1246 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00012: loss improved from 0.34976 to 0.34926, saving model to results/dnn4/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 99s 706us/step - loss: 0.3474 - acc: 0.8412 - val_loss: 0.1369 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00013: loss improved from 0.34926 to 0.34741, saving model to results/dnn4/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 100s 711us/step - loss: 0.3471 - acc: 0.8421 - val_loss: 0.1306 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00014: loss improved from 0.34741 to 0.34712, saving model to results/dnn4/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 101s 717us/step - loss: 0.3468 - acc: 0.8422 - val_loss: 0.1168 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00015: loss improved from 0.34712 to 0.34677, saving model to results/dnn4/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 102s 725us/step - loss: 0.3461 - acc: 0.8422 - val_loss: 0.1193 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00016: loss improved from 0.34677 to 0.34612, saving model to results/dnn4/checkpoint-16.hdf5\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 101s 717us/step - loss: 0.3453 - acc: 0.8425 - val_loss: 0.1281 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00017: loss improved from 0.34612 to 0.34529, saving model to results/dnn4/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 112s 798us/step - loss: 0.3463 - acc: 0.8421 - val_loss: 0.1259 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.34529\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 109s 779us/step - loss: 0.3463 - acc: 0.8423 - val_loss: 0.1185 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.34529\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 113s 809us/step - loss: 0.3451 - acc: 0.8427 - val_loss: 0.1262 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00020: loss improved from 0.34529 to 0.34512, saving model to results/dnn4/checkpoint-20.hdf5\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 106s 755us/step - loss: 0.3452 - acc: 0.8436 - val_loss: 0.1357 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.34512\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 106s 755us/step - loss: 0.3450 - acc: 0.8435 - val_loss: 0.1463 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00022: loss improved from 0.34512 to 0.34503, saving model to results/dnn4/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 105s 746us/step - loss: 0.3443 - acc: 0.8437 - val_loss: 0.1107 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00023: loss improved from 0.34503 to 0.34432, saving model to results/dnn4/checkpoint-23.hdf5\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 101s 721us/step - loss: 0.3428 - acc: 0.8445 - val_loss: 0.1174 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00024: loss improved from 0.34432 to 0.34278, saving model to results/dnn4/checkpoint-24.hdf5\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 99s 706us/step - loss: 0.3435 - acc: 0.8438 - val_loss: 0.1363 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.34278\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn4/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn4/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn4/dnn4_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:76: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 105s 751us/step - loss: 0.4294 - acc: 0.7701 - val_loss: 0.1727 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.42945, saving model to results/dnn5/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 100s 711us/step - loss: 0.4065 - acc: 0.7954 - val_loss: 0.1211 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00002: loss improved from 0.42945 to 0.40646, saving model to results/dnn5/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 101s 720us/step - loss: 0.4022 - acc: 0.7982 - val_loss: 0.1340 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00003: loss improved from 0.40646 to 0.40221, saving model to results/dnn5/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 101s 720us/step - loss: 0.3964 - acc: 0.8022 - val_loss: 0.1620 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00004: loss improved from 0.40221 to 0.39639, saving model to results/dnn5/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 107s 760us/step - loss: 0.3951 - acc: 0.8064 - val_loss: 0.1292 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00005: loss improved from 0.39639 to 0.39512, saving model to results/dnn5/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 107s 763us/step - loss: 0.3699 - acc: 0.8236 - val_loss: 0.1295 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00006: loss improved from 0.39512 to 0.36990, saving model to results/dnn5/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 105s 746us/step - loss: 0.3630 - acc: 0.8288 - val_loss: 0.1073 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00007: loss improved from 0.36990 to 0.36299, saving model to results/dnn5/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 104s 743us/step - loss: 0.3581 - acc: 0.8340 - val_loss: 0.1396 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00008: loss improved from 0.36299 to 0.35806, saving model to results/dnn5/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 108s 767us/step - loss: 0.3570 - acc: 0.8340 - val_loss: 0.1183 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00009: loss improved from 0.35806 to 0.35698, saving model to results/dnn5/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 110s 783us/step - loss: 0.3526 - acc: 0.8379 - val_loss: 0.1388 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00010: loss improved from 0.35698 to 0.35255, saving model to results/dnn5/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 111s 793us/step - loss: 0.3546 - acc: 0.8366 - val_loss: 0.1186 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.35255\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 105s 747us/step - loss: 0.3516 - acc: 0.8384 - val_loss: 0.1045 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00012: loss improved from 0.35255 to 0.35162, saving model to results/dnn5/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 108s 773us/step - loss: 0.3512 - acc: 0.8390 - val_loss: 0.1175 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00013: loss improved from 0.35162 to 0.35121, saving model to results/dnn5/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 108s 766us/step - loss: 0.3489 - acc: 0.8406 - val_loss: 0.1317 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00014: loss improved from 0.35121 to 0.34888, saving model to results/dnn5/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 106s 758us/step - loss: 0.3492 - acc: 0.8401 - val_loss: 0.1294 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.34888\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.3491 - acc: 0.8401 - val_loss: 0.1247 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.34888\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 104s 743us/step - loss: 0.3482 - acc: 0.8408 - val_loss: 0.1260 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00017: loss improved from 0.34888 to 0.34824, saving model to results/dnn5/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.3537 - acc: 0.8397 - val_loss: 0.1315 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.34824\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 105s 746us/step - loss: 0.3463 - acc: 0.8419 - val_loss: 0.1233 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00019: loss improved from 0.34824 to 0.34629, saving model to results/dnn5/checkpoint-19.hdf5\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 105s 748us/step - loss: 0.3499 - acc: 0.8398 - val_loss: 0.1260 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.34629\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 107s 764us/step - loss: 0.3471 - acc: 0.8423 - val_loss: 0.1238 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.34629\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 109s 778us/step - loss: 0.3454 - acc: 0.8430 - val_loss: 0.1284 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00022: loss improved from 0.34629 to 0.34545, saving model to results/dnn5/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 110s 785us/step - loss: 0.3459 - acc: 0.8424 - val_loss: 0.1103 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.34545\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 111s 792us/step - loss: 0.3458 - acc: 0.8431 - val_loss: 0.1229 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.34545\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 109s 781us/step - loss: 0.3442 - acc: 0.8439 - val_loss: 0.1220 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00025: loss improved from 0.34545 to 0.34418, saving model to results/dnn5/checkpoint-25.hdf5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "X_train = np.array(trainX)\n",
    "X_test = np.array(testT)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=43,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/dnn5/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('results/dnn5/training_set_dnnanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=batch_size, nb_epoch=25, callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/dnn5/dnn5_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "{'name': 'sequential_1', 'layers': [{'class_name': 'GRU', 'config': {'name': 'gru_1', 'trainable': True, 'batch_input_shape': (None, None, 43), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 4, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1, 'reset_after': False}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_1', 'trainable': True, 'activation': 'sigmoid'}}]}\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.5033 - acc: 0.7027 - val_loss: 0.1766 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86227, saving model to results/gru/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 12s 84us/step - loss: 0.4696 - acc: 0.7270 - val_loss: 0.1667 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86227 to 0.89130, saving model to results/gru/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4668 - acc: 0.7296 - val_loss: 0.1818 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89130\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 13s 90us/step - loss: 0.4641 - acc: 0.7314 - val_loss: 0.1694 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89130 to 0.90037, saving model to results/gru/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 14s 97us/step - loss: 0.4628 - acc: 0.7302 - val_loss: 0.1711 - val_acc: 0.8946\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90037\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4618 - acc: 0.7302 - val_loss: 0.1660 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90037 to 0.91137, saving model to results/gru/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4609 - acc: 0.7299 - val_loss: 0.1771 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91137\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4601 - acc: 0.7305 - val_loss: 0.1614 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91137 to 0.92110, saving model to results/gru/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 12s 84us/step - loss: 0.4596 - acc: 0.7290 - val_loss: 0.1537 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92110\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4585 - acc: 0.7312 - val_loss: 0.1719 - val_acc: 0.8964\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92110\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 12s 89us/step - loss: 0.4579 - acc: 0.7306 - val_loss: 0.1640 - val_acc: 0.9035\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92110\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 12s 86us/step - loss: 0.4571 - acc: 0.7327 - val_loss: 0.1635 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92110\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4565 - acc: 0.7328 - val_loss: 0.1501 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92110\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 12s 84us/step - loss: 0.4554 - acc: 0.7348 - val_loss: 0.1536 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.92110 to 0.92575, saving model to results/gru/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 13s 90us/step - loss: 0.4537 - acc: 0.7362 - val_loss: 0.1809 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92575\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 14s 103us/step - loss: 0.4515 - acc: 0.7408 - val_loss: 0.1645 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92575\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 18s 126us/step - loss: 0.4475 - acc: 0.7467 - val_loss: 0.1495 - val_acc: 0.9366\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.92575 to 0.93655, saving model to results/gru/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4424 - acc: 0.7567 - val_loss: 0.1726 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.93655 to 0.93949, saving model to results/gru/checkpoint-18.hdf5\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.4360 - acc: 0.7642 - val_loss: 0.1549 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.93949 to 0.95318, saving model to results/gru/checkpoint-19.hdf5\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.4291 - acc: 0.7729 - val_loss: 0.1654 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.95318\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.4224 - acc: 0.7824 - val_loss: 0.1796 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.95318\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 19s 132us/step - loss: 0.4161 - acc: 0.7891 - val_loss: 0.1395 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.95318 to 0.99869, saving model to results/gru/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.4102 - acc: 0.7952 - val_loss: 0.1487 - val_acc: 0.9986\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99869\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 18s 128us/step - loss: 0.4054 - acc: 0.8013 - val_loss: 0.1783 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99869\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 18s 130us/step - loss: 0.4010 - acc: 0.8048 - val_loss: 0.1617 - val_acc: 0.9561\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99869\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "print(model.get_config())\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/gru/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/gru/gru_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(8, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 17s 123us/step - loss: 0.4878 - acc: 0.7141 - val_loss: 0.1687 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87989, saving model to results/gru1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 0.4659 - acc: 0.7283 - val_loss: 0.1901 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.87989\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.4634 - acc: 0.7302 - val_loss: 0.1956 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87989 to 0.88049, saving model to results/gru1/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.4613 - acc: 0.7326 - val_loss: 0.1687 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.88049 to 0.88511, saving model to results/gru1/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.4603 - acc: 0.7308 - val_loss: 0.1613 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.88511 to 0.91480, saving model to results/gru1/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.4595 - acc: 0.7323 - val_loss: 0.1720 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91480\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.4587 - acc: 0.7324 - val_loss: 0.1603 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91480\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4579 - acc: 0.7313 - val_loss: 0.1683 - val_acc: 0.9023\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91480\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.4566 - acc: 0.7335 - val_loss: 0.1646 - val_acc: 0.8933\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91480\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 15s 108us/step - loss: 0.4549 - acc: 0.7377 - val_loss: 0.1538 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91480\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 15s 108us/step - loss: 0.4474 - acc: 0.7494 - val_loss: 0.1417 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.91480 to 0.95346, saving model to results/gru1/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 15s 108us/step - loss: 0.4291 - acc: 0.7716 - val_loss: 0.1329 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.95346 to 0.99723, saving model to results/gru1/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 15s 109us/step - loss: 0.4069 - acc: 0.7900 - val_loss: 0.1423 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99723\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 15s 107us/step - loss: 0.3945 - acc: 0.8007 - val_loss: 0.1103 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99723 to 0.99806, saving model to results/gru1/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 25s 178us/step - loss: 0.3890 - acc: 0.8066 - val_loss: 0.1620 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99806\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 0.3878 - acc: 0.8071 - val_loss: 0.1415 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99806\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3846 - acc: 0.8112 - val_loss: 0.1877 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99806\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 0.3839 - acc: 0.8115 - val_loss: 0.1218 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99806\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.3828 - acc: 0.8127 - val_loss: 0.1451 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99806\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.3818 - acc: 0.8136 - val_loss: 0.1258 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99806\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 18s 129us/step - loss: 0.3808 - acc: 0.8146 - val_loss: 0.1340 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99806\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3803 - acc: 0.8142 - val_loss: 0.1100 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99806\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 14s 102us/step - loss: 0.3791 - acc: 0.8158 - val_loss: 0.1367 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99806\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 14s 100us/step - loss: 0.3787 - acc: 0.8166 - val_loss: 0.1649 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99806\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 14s 99us/step - loss: 0.3783 - acc: 0.8157 - val_loss: 0.1471 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99806\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/gru1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/gru1/gru1_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(16, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 24s 170us/step - loss: 0.4772 - acc: 0.7204 - val_loss: 0.1790 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88249, saving model to results/gru2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 20s 145us/step - loss: 0.4636 - acc: 0.7293 - val_loss: 0.1599 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88249 to 0.92090, saving model to results/gru2/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.4615 - acc: 0.7299 - val_loss: 0.1699 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92090\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.4599 - acc: 0.7309 - val_loss: 0.1708 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92090\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.4589 - acc: 0.7317 - val_loss: 0.1694 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92090\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 21s 152us/step - loss: 0.4569 - acc: 0.7323 - val_loss: 0.1547 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92090\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 22s 155us/step - loss: 0.4529 - acc: 0.7381 - val_loss: 0.1609 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92090\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 21s 152us/step - loss: 0.4403 - acc: 0.7548 - val_loss: 0.1446 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92090 to 0.99387, saving model to results/gru2/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 21s 151us/step - loss: 0.4122 - acc: 0.7823 - val_loss: 0.1320 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99387 to 0.99492, saving model to results/gru2/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 21s 151us/step - loss: 0.3967 - acc: 0.7957 - val_loss: 0.1354 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99492 to 0.99569, saving model to results/gru2/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 21s 147us/step - loss: 0.3903 - acc: 0.8021 - val_loss: 0.1302 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99569 to 0.99709, saving model to results/gru2/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 20s 144us/step - loss: 0.3856 - acc: 0.8078 - val_loss: 0.1159 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99709\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 19s 137us/step - loss: 0.3833 - acc: 0.8086 - val_loss: 0.1234 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99709\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 19s 137us/step - loss: 0.3810 - acc: 0.8129 - val_loss: 0.1043 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99709 to 0.99880, saving model to results/gru2/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 21s 147us/step - loss: 0.3790 - acc: 0.8147 - val_loss: 0.1040 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.99880 to 0.99929, saving model to results/gru2/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.3791 - acc: 0.8140 - val_loss: 0.1367 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99929\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3782 - acc: 0.8147 - val_loss: 0.1550 - val_acc: 0.9603\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99929\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3767 - acc: 0.8159 - val_loss: 0.1231 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99929\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 20s 146us/step - loss: 0.3753 - acc: 0.8188 - val_loss: 0.1222 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99929\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3752 - acc: 0.8191 - val_loss: 0.1712 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99929\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 23s 162us/step - loss: 0.3740 - acc: 0.8193 - val_loss: 0.1245 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99929\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 23s 161us/step - loss: 0.3728 - acc: 0.8199 - val_loss: 0.1212 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99929\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 23s 163us/step - loss: 0.3724 - acc: 0.8209 - val_loss: 0.1324 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99929\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.3715 - acc: 0.8218 - val_loss: 0.1261 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99929\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.3704 - acc: 0.8232 - val_loss: 0.1362 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nloss, accuracy = model.evaluate(X_test, y_test)\\nprint(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\\ny_pred = model.predict_classes(X_test)\\nnp.savetxt(\\'results/gru2/gru2predicted.txt\\', np.transpose([y_test,y_pred]), fmt=\\'%01d\\')\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/gru2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis2.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/gru2/gru2_model.hdf5\")\n",
    "\n",
    "'''\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "np.savetxt('results/gru2/gru2predicted.txt', np.transpose([y_test,y_pred]), fmt='%01d')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(32, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 30s 211us/step - loss: 0.4742 - acc: 0.7196 - val_loss: 0.1975 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85583, saving model to results/gru3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 28s 199us/step - loss: 0.4629 - acc: 0.7285 - val_loss: 0.1606 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85583 to 0.95723, saving model to results/gru3/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 30s 211us/step - loss: 0.4590 - acc: 0.7304 - val_loss: 0.1690 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95723\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 28s 202us/step - loss: 0.4572 - acc: 0.7299 - val_loss: 0.1701 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95723\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 28s 201us/step - loss: 0.4563 - acc: 0.7304 - val_loss: 0.1486 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95723\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 26s 185us/step - loss: 0.4555 - acc: 0.7316 - val_loss: 0.1864 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95723\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 26s 187us/step - loss: 0.4548 - acc: 0.7307 - val_loss: 0.1887 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95723\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 26s 185us/step - loss: 0.4537 - acc: 0.7317 - val_loss: 0.1828 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95723\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 27s 194us/step - loss: 0.4515 - acc: 0.7347 - val_loss: 0.1555 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95723\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 28s 203us/step - loss: 0.4359 - acc: 0.7558 - val_loss: 0.1738 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95723\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 29s 204us/step - loss: 0.4058 - acc: 0.7871 - val_loss: 0.1311 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.95723 to 0.99755, saving model to results/gru3/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 28s 202us/step - loss: 0.3932 - acc: 0.7983 - val_loss: 0.1516 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99755\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 29s 205us/step - loss: 0.3869 - acc: 0.8044 - val_loss: 0.1049 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.99755 to 0.99837, saving model to results/gru3/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 29s 207us/step - loss: 0.3821 - acc: 0.8101 - val_loss: 0.1784 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99837\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 29s 206us/step - loss: 0.3785 - acc: 0.8133 - val_loss: 0.1254 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.99837 to 0.99866, saving model to results/gru3/checkpoint-15.hdf5\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 28s 201us/step - loss: 0.3776 - acc: 0.8134 - val_loss: 0.1439 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99866\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 27s 195us/step - loss: 0.3740 - acc: 0.8180 - val_loss: 0.1296 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.99866 to 0.99954, saving model to results/gru3/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 28s 197us/step - loss: 0.3732 - acc: 0.8191 - val_loss: 0.1359 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99954\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 28s 198us/step - loss: 0.3694 - acc: 0.8218 - val_loss: 0.1358 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99954\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 27s 192us/step - loss: 0.3683 - acc: 0.8235 - val_loss: 0.1402 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99954\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 26s 187us/step - loss: 0.3667 - acc: 0.8245 - val_loss: 0.1110 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99954\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 27s 195us/step - loss: 0.3640 - acc: 0.8267 - val_loss: 0.1321 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99954\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 28s 201us/step - loss: 0.3594 - acc: 0.8314 - val_loss: 0.1325 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99954\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 28s 203us/step - loss: 0.3565 - acc: 0.8338 - val_loss: 0.1270 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99954\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 29s 207us/step - loss: 0.3541 - acc: 0.8363 - val_loss: 0.1102 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99954\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(GRU(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/gru3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/gru3/gru3_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_5', 'layers': [{'class_name': 'LSTM', 'config': {'name': 'lstm_1', 'trainable': True, 'batch_input_shape': (None, None, 43), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 4, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_5', 'trainable': True, 'activation': 'sigmoid'}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 16s 111us/step - loss: 0.5036 - acc: 0.7034 - val_loss: 0.1767 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87063, saving model to results/lstm/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4696 - acc: 0.7265 - val_loss: 0.1559 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87063 to 0.92061, saving model to results/lstm/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4666 - acc: 0.7281 - val_loss: 0.1779 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92061\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4646 - acc: 0.7295 - val_loss: 0.1747 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92061\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 12s 85us/step - loss: 0.4636 - acc: 0.7285 - val_loss: 0.1699 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92061\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 12s 84us/step - loss: 0.4621 - acc: 0.7301 - val_loss: 0.1657 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92061\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 12s 85us/step - loss: 0.4609 - acc: 0.7294 - val_loss: 0.1643 - val_acc: 0.8989\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92061\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 12s 85us/step - loss: 0.4598 - acc: 0.7306 - val_loss: 0.1534 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92061 to 0.92218, saving model to results/lstm/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 13s 89us/step - loss: 0.4592 - acc: 0.7299 - val_loss: 0.1820 - val_acc: 0.9027\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92218\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4584 - acc: 0.7305 - val_loss: 0.1697 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92218\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4576 - acc: 0.7310 - val_loss: 0.1631 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92218 to 0.93276, saving model to results/lstm/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 13s 90us/step - loss: 0.4572 - acc: 0.7299 - val_loss: 0.1572 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93276\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 12s 86us/step - loss: 0.4567 - acc: 0.7303 - val_loss: 0.1828 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93276\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4559 - acc: 0.7303 - val_loss: 0.1808 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93276\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4554 - acc: 0.7306 - val_loss: 0.1890 - val_acc: 0.8912\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93276\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 12s 86us/step - loss: 0.4548 - acc: 0.7326 - val_loss: 0.1690 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93276\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 13s 93us/step - loss: 0.4550 - acc: 0.7310 - val_loss: 0.1658 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93276\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 13s 92us/step - loss: 0.4542 - acc: 0.7313 - val_loss: 0.1674 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93276\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 14s 98us/step - loss: 0.4542 - acc: 0.7323 - val_loss: 0.1623 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93276\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 13s 95us/step - loss: 0.4537 - acc: 0.7322 - val_loss: 0.1713 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93276\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4531 - acc: 0.7315 - val_loss: 0.1662 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93276\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 12s 87us/step - loss: 0.4524 - acc: 0.7343 - val_loss: 0.1573 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93276\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.4509 - acc: 0.7371 - val_loss: 0.1583 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.93276 to 0.93305, saving model to results/lstm/checkpoint-23.hdf5\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 13s 93us/step - loss: 0.4481 - acc: 0.7424 - val_loss: 0.1561 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.93305 to 0.93966, saving model to results/lstm/checkpoint-24.hdf5\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 13s 94us/step - loss: 0.4459 - acc: 0.7475 - val_loss: 0.1756 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93966\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "#print(X_train.shape)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "print(model.get_config())\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/lstm/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm/lstm_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(8, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 22s 156us/step - loss: 0.4939 - acc: 0.7081 - val_loss: 0.1722 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86552, saving model to results/lstm1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4663 - acc: 0.7283 - val_loss: 0.1702 - val_acc: 0.8965\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86552 to 0.89646, saving model to results/lstm1/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.4629 - acc: 0.7303 - val_loss: 0.1735 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89646\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.4608 - acc: 0.7309 - val_loss: 0.1679 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89646\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.4580 - acc: 0.7348 - val_loss: 0.1508 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.89646 to 0.97739, saving model to results/lstm1/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.4514 - acc: 0.7444 - val_loss: 0.1645 - val_acc: 0.8988\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97739\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.4291 - acc: 0.7705 - val_loss: 0.1471 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.97739 to 0.99316, saving model to results/lstm1/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.4082 - acc: 0.7885 - val_loss: 0.1128 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99316 to 0.99812, saving model to results/lstm1/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3985 - acc: 0.7976 - val_loss: 0.1286 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99812\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3944 - acc: 0.7994 - val_loss: 0.1368 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99812\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 18s 132us/step - loss: 0.3910 - acc: 0.8018 - val_loss: 0.1595 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99812\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 18s 131us/step - loss: 0.3894 - acc: 0.8038 - val_loss: 0.1550 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99812\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.3885 - acc: 0.8043 - val_loss: 0.1044 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99812\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 20s 141us/step - loss: 0.3875 - acc: 0.8060 - val_loss: 0.1271 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99812\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 20s 142us/step - loss: 0.3864 - acc: 0.8071 - val_loss: 0.1245 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99812\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 21s 147us/step - loss: 0.3858 - acc: 0.8077 - val_loss: 0.1234 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99812\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 20s 146us/step - loss: 0.3855 - acc: 0.8070 - val_loss: 0.1279 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99812\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 19s 138us/step - loss: 0.3844 - acc: 0.8091 - val_loss: 0.1197 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99812\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.3851 - acc: 0.8078 - val_loss: 0.1463 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99812\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 19s 134us/step - loss: 0.3843 - acc: 0.8083 - val_loss: 0.1194 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99812\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.3834 - acc: 0.8093 - val_loss: 0.0996 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.99812 to 0.99818, saving model to results/lstm1/checkpoint-21.hdf5\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 18s 131us/step - loss: 0.3839 - acc: 0.8084 - val_loss: 0.1135 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99818\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 18s 127us/step - loss: 0.3836 - acc: 0.8098 - val_loss: 0.1007 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99818\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3825 - acc: 0.8114 - val_loss: 0.1549 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99818\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3823 - acc: 0.8104 - val_loss: 0.1563 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99818\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/lstm1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm1/lstm1_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(16, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 31s 223us/step - loss: 0.4810 - acc: 0.7170 - val_loss: 0.1539 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93407, saving model to results/lstm2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 26s 188us/step - loss: 0.4642 - acc: 0.7283 - val_loss: 0.1572 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93407\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 27s 191us/step - loss: 0.4619 - acc: 0.7303 - val_loss: 0.1983 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93407\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 26s 182us/step - loss: 0.4590 - acc: 0.7316 - val_loss: 0.1599 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93407\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 26s 183us/step - loss: 0.4565 - acc: 0.7335 - val_loss: 0.1565 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93407\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 26s 183us/step - loss: 0.4494 - acc: 0.7447 - val_loss: 0.1603 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93407\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 25s 176us/step - loss: 0.4180 - acc: 0.7765 - val_loss: 0.1389 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.93407 to 0.99632, saving model to results/lstm2/checkpoint-07.hdf5\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 26s 184us/step - loss: 0.3975 - acc: 0.7950 - val_loss: 0.1045 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99632 to 0.99877, saving model to results/lstm2/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 26s 185us/step - loss: 0.3911 - acc: 0.8027 - val_loss: 0.1291 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99877\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 27s 193us/step - loss: 0.3871 - acc: 0.8044 - val_loss: 0.1737 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99877\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 27s 194us/step - loss: 0.3835 - acc: 0.8090 - val_loss: 0.1066 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99877\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 30s 212us/step - loss: 0.3808 - acc: 0.8109 - val_loss: 0.1172 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99877\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 33s 232us/step - loss: 0.3795 - acc: 0.8127 - val_loss: 0.1436 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99877\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 30s 211us/step - loss: 0.3770 - acc: 0.8156 - val_loss: 0.1241 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99877\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 29s 207us/step - loss: 0.3759 - acc: 0.8158 - val_loss: 0.1355 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99877\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 33s 234us/step - loss: 0.3759 - acc: 0.8158 - val_loss: 0.1315 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99877\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 28s 199us/step - loss: 0.3746 - acc: 0.8164 - val_loss: 0.1475 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99877\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 29s 210us/step - loss: 0.3741 - acc: 0.8183 - val_loss: 0.1438 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99877\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 32s 231us/step - loss: 0.3732 - acc: 0.8183 - val_loss: 0.1163 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99877\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 29s 208us/step - loss: 0.3733 - acc: 0.8176 - val_loss: 0.1371 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99877\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 28s 203us/step - loss: 0.3721 - acc: 0.8197 - val_loss: 0.1421 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99877\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 29s 206us/step - loss: 0.3716 - acc: 0.8196 - val_loss: 0.1334 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99877\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 27s 193us/step - loss: 0.3713 - acc: 0.8195 - val_loss: 0.1335 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99877\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 29s 204us/step - loss: 0.3710 - acc: 0.8212 - val_loss: 0.1154 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.99877 to 0.99903, saving model to results/lstm2/checkpoint-24.hdf5\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 29s 208us/step - loss: 0.3706 - acc: 0.8210 - val_loss: 0.1284 - val_acc: 0.9986\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99903\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/lstm2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm2/lstm2_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(32, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 47s 336us/step - loss: 0.4767 - acc: 0.7190 - val_loss: 0.1777 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88178, saving model to results/lstm3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 37s 262us/step - loss: 0.4630 - acc: 0.7293 - val_loss: 0.1671 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88178 to 0.91551, saving model to results/lstm3/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 36s 254us/step - loss: 0.4598 - acc: 0.7310 - val_loss: 0.1665 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91551 to 0.92680, saving model to results/lstm3/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 31s 223us/step - loss: 0.4580 - acc: 0.7294 - val_loss: 0.1612 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92680\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 34s 244us/step - loss: 0.4563 - acc: 0.7295 - val_loss: 0.1368 - val_acc: 0.9996\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92680 to 0.99960, saving model to results/lstm3/checkpoint-05.hdf5\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 40s 285us/step - loss: 0.4555 - acc: 0.7302 - val_loss: 0.1670 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99960\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 43s 305us/step - loss: 0.4544 - acc: 0.7317 - val_loss: 0.1468 - val_acc: 0.9438\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99960\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 37s 266us/step - loss: 0.4525 - acc: 0.7332 - val_loss: 0.1716 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99960\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 36s 254us/step - loss: 0.4332 - acc: 0.7586 - val_loss: 0.1403 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99960\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 35s 250us/step - loss: 0.3992 - acc: 0.7918 - val_loss: 0.1437 - val_acc: 0.9402\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99960\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 35s 246us/step - loss: 0.3880 - acc: 0.8022 - val_loss: 0.1356 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99960\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 36s 255us/step - loss: 0.3855 - acc: 0.8066 - val_loss: 0.1206 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99960\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 37s 263us/step - loss: 0.3818 - acc: 0.8088 - val_loss: 0.1380 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99960\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 36s 255us/step - loss: 0.3804 - acc: 0.8100 - val_loss: 0.1369 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99960\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 34s 239us/step - loss: 0.3786 - acc: 0.8124 - val_loss: 0.1220 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99960\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 35s 246us/step - loss: 0.3782 - acc: 0.8128 - val_loss: 0.1300 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99960\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 33s 237us/step - loss: 0.3774 - acc: 0.8130 - val_loss: 0.1541 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99960\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 36s 255us/step - loss: 0.3761 - acc: 0.8145 - val_loss: 0.1988 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99960\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 34s 241us/step - loss: 0.3746 - acc: 0.8149 - val_loss: 0.1513 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99960\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 31s 219us/step - loss: 0.3742 - acc: 0.8154 - val_loss: 0.1299 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99960\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 31s 219us/step - loss: 0.3738 - acc: 0.8159 - val_loss: 0.1314 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99960\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 31s 223us/step - loss: 0.3730 - acc: 0.8169 - val_loss: 0.1330 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99960\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 32s 228us/step - loss: 0.3722 - acc: 0.8172 - val_loss: 0.1305 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99960\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 35s 250us/step - loss: 0.3712 - acc: 0.8192 - val_loss: 0.1445 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99960\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 33s 234us/step - loss: 0.3707 - acc: 0.8195 - val_loss: 0.1345 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99960\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/lstm3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm3/lstm3_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140272, 1, 43)\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(4, input_shape=(None, 43))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_1', 'layers': [{'class_name': 'SimpleRNN', 'config': {'name': 'simple_rnn_1', 'trainable': True, 'batch_input_shape': (None, None, 43), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 4, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_1', 'trainable': True, 'activation': 'sigmoid'}}]}\n",
      "WARNING:tensorflow:From C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 10s 73us/step - loss: 0.5011 - acc: 0.7052 - val_loss: 0.1783 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85822, saving model to results/rnn/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 9s 65us/step - loss: 0.4696 - acc: 0.7275 - val_loss: 0.1640 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85822 to 0.92267, saving model to results/rnn/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 9s 64us/step - loss: 0.4672 - acc: 0.7287 - val_loss: 0.1539 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92267\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 9s 67us/step - loss: 0.4649 - acc: 0.7297 - val_loss: 0.1675 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92267\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.4637 - acc: 0.7292 - val_loss: 0.1726 - val_acc: 0.9024\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92267\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 10s 73us/step - loss: 0.4626 - acc: 0.7302 - val_loss: 0.1600 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92267 to 0.92272, saving model to results/rnn/checkpoint-06.hdf5\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 10s 74us/step - loss: 0.4620 - acc: 0.7302 - val_loss: 0.1684 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92272\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 11s 76us/step - loss: 0.4612 - acc: 0.7303 - val_loss: 0.1741 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92272\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 10s 73us/step - loss: 0.4605 - acc: 0.7308 - val_loss: 0.1586 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92272\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 10s 70us/step - loss: 0.4602 - acc: 0.7305 - val_loss: 0.1864 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92272\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 10s 73us/step - loss: 0.4594 - acc: 0.7316 - val_loss: 0.1648 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92272\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 10s 74us/step - loss: 0.4585 - acc: 0.7318 - val_loss: 0.1660 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92272\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 10s 70us/step - loss: 0.4581 - acc: 0.7338 - val_loss: 0.1573 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92272 to 0.92791, saving model to results/rnn/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4563 - acc: 0.7359 - val_loss: 0.1551 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92791\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.4545 - acc: 0.7391 - val_loss: 0.1622 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92791\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4530 - acc: 0.7422 - val_loss: 0.1702 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92791\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.4503 - acc: 0.7470 - val_loss: 0.1557 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.92791 to 0.97448, saving model to results/rnn/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 10s 68us/step - loss: 0.4484 - acc: 0.7509 - val_loss: 0.1562 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.97448\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 9s 65us/step - loss: 0.4459 - acc: 0.7538 - val_loss: 0.1664 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.97448\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.4435 - acc: 0.7585 - val_loss: 0.1693 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97448\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.4406 - acc: 0.7638 - val_loss: 0.1598 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.97448\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 9s 67us/step - loss: 0.4386 - acc: 0.7666 - val_loss: 0.1378 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.97448 to 0.99869, saving model to results/rnn/checkpoint-22.hdf5\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 11s 78us/step - loss: 0.4356 - acc: 0.7704 - val_loss: 0.1999 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99869\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 10s 69us/step - loss: 0.4335 - acc: 0.7749 - val_loss: 0.1598 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99869\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 9s 66us/step - loss: 0.4313 - acc: 0.7777 - val_loss: 0.1506 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99869\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(4,input_dim=43))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "print(model.get_config())\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/rnn/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/rnn/rnn_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(8, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 15s 109us/step - loss: 0.4859 - acc: 0.7116 - val_loss: 0.1790 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85571, saving model to results/rnn1/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 15s 105us/step - loss: 0.4664 - acc: 0.7274 - val_loss: 0.1758 - val_acc: 0.8741\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85571 to 0.87413, saving model to results/rnn1/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 14s 103us/step - loss: 0.4635 - acc: 0.7295 - val_loss: 0.1479 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87413 to 0.92358, saving model to results/rnn1/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 14s 102us/step - loss: 0.4618 - acc: 0.7299 - val_loss: 0.1452 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92358 to 0.92466, saving model to results/rnn1/checkpoint-04.hdf5\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 15s 108us/step - loss: 0.4607 - acc: 0.7302 - val_loss: 0.1543 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92466\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 0.4602 - acc: 0.7318 - val_loss: 0.1804 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92466\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 17s 120us/step - loss: 0.4596 - acc: 0.7309 - val_loss: 0.1993 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92466\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 15s 109us/step - loss: 0.4596 - acc: 0.7313 - val_loss: 0.1709 - val_acc: 0.8815\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92466\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 14s 97us/step - loss: 0.4590 - acc: 0.7323 - val_loss: 0.1616 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92466\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 13s 93us/step - loss: 0.4583 - acc: 0.7323 - val_loss: 0.1586 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92466 to 0.93088, saving model to results/rnn1/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 13s 94us/step - loss: 0.4583 - acc: 0.7322 - val_loss: 0.1602 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93088\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 13s 91us/step - loss: 0.4582 - acc: 0.7312 - val_loss: 0.1759 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93088\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 12s 85us/step - loss: 0.4578 - acc: 0.7312 - val_loss: 0.1322 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.93088 to 0.99949, saving model to results/rnn1/checkpoint-13.hdf5\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4577 - acc: 0.7331 - val_loss: 0.1804 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99949\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 11s 82us/step - loss: 0.4567 - acc: 0.7338 - val_loss: 0.2005 - val_acc: 0.8807\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99949\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 11s 79us/step - loss: 0.4555 - acc: 0.7355 - val_loss: 0.1398 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99949\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4501 - acc: 0.7458 - val_loss: 0.1756 - val_acc: 0.8786\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99949\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4332 - acc: 0.7688 - val_loss: 0.1764 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99949\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 11s 75us/step - loss: 0.4120 - acc: 0.7912 - val_loss: 0.1300 - val_acc: 0.9970\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99949\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 10s 74us/step - loss: 0.4003 - acc: 0.7992 - val_loss: 0.1606 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99949\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 10s 74us/step - loss: 0.3937 - acc: 0.8044 - val_loss: 0.0748 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99949\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 11s 77us/step - loss: 0.3906 - acc: 0.8074 - val_loss: 0.1926 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99949\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 11s 81us/step - loss: 0.3881 - acc: 0.8105 - val_loss: 0.1285 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99949\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 12s 88us/step - loss: 0.3864 - acc: 0.8109 - val_loss: 0.1130 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99949\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 13s 96us/step - loss: 0.3847 - acc: 0.8139 - val_loss: 0.1847 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99949\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(8,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(8, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/rnn1/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/rnn1/rnn1_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(16, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4768 - acc: 0.7190 - val_loss: 0.1766 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87667, saving model to results/rnn2/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 16s 115us/step - loss: 0.4650 - acc: 0.7277 - val_loss: 0.1740 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87667 to 0.90165, saving model to results/rnn2/checkpoint-02.hdf5\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.4627 - acc: 0.7307 - val_loss: 0.1943 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90165 to 0.92324, saving model to results/rnn2/checkpoint-03.hdf5\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 15s 105us/step - loss: 0.4613 - acc: 0.7298 - val_loss: 0.1625 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92324\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 14s 99us/step - loss: 0.4601 - acc: 0.7316 - val_loss: 0.1699 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92324\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 14s 98us/step - loss: 0.4598 - acc: 0.7308 - val_loss: 0.1885 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92324\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 14s 100us/step - loss: 0.4585 - acc: 0.7321 - val_loss: 0.1683 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92324\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 14s 99us/step - loss: 0.4563 - acc: 0.7357 - val_loss: 0.1559 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92324\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 14s 103us/step - loss: 0.4322 - acc: 0.7647 - val_loss: 0.1343 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92324 to 0.99592, saving model to results/rnn2/checkpoint-09.hdf5\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 14s 103us/step - loss: 0.4048 - acc: 0.7895 - val_loss: 0.1420 - val_acc: 0.9976\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99592 to 0.99758, saving model to results/rnn2/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 14s 101us/step - loss: 0.3964 - acc: 0.7971 - val_loss: 0.1259 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99758 to 0.99792, saving model to results/rnn2/checkpoint-11.hdf5\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 15s 110us/step - loss: 0.3910 - acc: 0.8019 - val_loss: 0.1102 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.99792 to 0.99872, saving model to results/rnn2/checkpoint-12.hdf5\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3895 - acc: 0.8039 - val_loss: 0.1059 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99872\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 17s 118us/step - loss: 0.3877 - acc: 0.8062 - val_loss: 0.0880 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99872 to 0.99883, saving model to results/rnn2/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 16s 116us/step - loss: 0.3862 - acc: 0.8077 - val_loss: 0.1437 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99883\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 16s 114us/step - loss: 0.3847 - acc: 0.8097 - val_loss: 0.1745 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99883\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 16s 113us/step - loss: 0.3854 - acc: 0.8082 - val_loss: 0.1074 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99883\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3829 - acc: 0.8115 - val_loss: 0.1424 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99883\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 17s 121us/step - loss: 0.3831 - acc: 0.8124 - val_loss: 0.1049 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99883\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 17s 124us/step - loss: 0.3820 - acc: 0.8144 - val_loss: 0.1309 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99883\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 16s 117us/step - loss: 0.3812 - acc: 0.8146 - val_loss: 0.0848 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99883\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 17s 119us/step - loss: 0.3809 - acc: 0.8150 - val_loss: 0.1344 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99883\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 16s 112us/step - loss: 0.3798 - acc: 0.8166 - val_loss: 0.1775 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99883\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 15s 106us/step - loss: 0.3794 - acc: 0.8173 - val_loss: 0.1129 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99883\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 15s 106us/step - loss: 0.3790 - acc: 0.8177 - val_loss: 0.1105 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99883\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(16,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(16, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(16, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/rnn2/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/rnn2/rnn2_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(32, return_sequences=True, input_shape=(None, 43))`\n",
      "C:\\Users\\roysi\\Documents\\appprograms\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140272 samples, validate on 35069 samples\n",
      "Epoch 1/25\n",
      "140272/140272 [==============================] - 21s 150us/step - loss: 0.4752 - acc: 0.7188 - val_loss: 0.1480 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97548, saving model to results/rnn3/checkpoint-01.hdf5\n",
      "Epoch 2/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4652 - acc: 0.7297 - val_loss: 0.1630 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.97548\n",
      "Epoch 3/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4627 - acc: 0.7299 - val_loss: 0.1696 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.97548\n",
      "Epoch 4/25\n",
      "140272/140272 [==============================] - 20s 142us/step - loss: 0.4610 - acc: 0.7320 - val_loss: 0.1623 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97548\n",
      "Epoch 5/25\n",
      "140272/140272 [==============================] - 19s 134us/step - loss: 0.4596 - acc: 0.7310 - val_loss: 0.1657 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97548\n",
      "Epoch 6/25\n",
      "140272/140272 [==============================] - 17s 122us/step - loss: 0.4577 - acc: 0.7337 - val_loss: 0.1784 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97548\n",
      "Epoch 7/25\n",
      "140272/140272 [==============================] - 18s 129us/step - loss: 0.4557 - acc: 0.7389 - val_loss: 0.1944 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97548\n",
      "Epoch 8/25\n",
      "140272/140272 [==============================] - 19s 135us/step - loss: 0.4512 - acc: 0.7442 - val_loss: 0.1317 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.97548 to 0.99892, saving model to results/rnn3/checkpoint-08.hdf5\n",
      "Epoch 9/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4319 - acc: 0.7626 - val_loss: 0.1550 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99892\n",
      "Epoch 10/25\n",
      "140272/140272 [==============================] - 19s 133us/step - loss: 0.4042 - acc: 0.7863 - val_loss: 0.1205 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99892 to 0.99897, saving model to results/rnn3/checkpoint-10.hdf5\n",
      "Epoch 11/25\n",
      "140272/140272 [==============================] - 19s 134us/step - loss: 0.3969 - acc: 0.7931 - val_loss: 0.1119 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99897\n",
      "Epoch 12/25\n",
      "140272/140272 [==============================] - 23s 163us/step - loss: 0.3958 - acc: 0.7944 - val_loss: 0.1587 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99897\n",
      "Epoch 13/25\n",
      "140272/140272 [==============================] - 24s 172us/step - loss: 0.3915 - acc: 0.7992 - val_loss: 0.1478 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99897\n",
      "Epoch 14/25\n",
      "140272/140272 [==============================] - 26s 184us/step - loss: 0.3903 - acc: 0.8006 - val_loss: 0.1245 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99897 to 0.99900, saving model to results/rnn3/checkpoint-14.hdf5\n",
      "Epoch 15/25\n",
      "140272/140272 [==============================] - 23s 165us/step - loss: 0.3889 - acc: 0.8029 - val_loss: 0.1443 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99900\n",
      "Epoch 16/25\n",
      "140272/140272 [==============================] - 21s 151us/step - loss: 0.3871 - acc: 0.8054 - val_loss: 0.1390 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99900\n",
      "Epoch 17/25\n",
      "140272/140272 [==============================] - 21s 147us/step - loss: 0.3863 - acc: 0.8060 - val_loss: 0.0985 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.99900 to 0.99943, saving model to results/rnn3/checkpoint-17.hdf5\n",
      "Epoch 18/25\n",
      "140272/140272 [==============================] - 22s 155us/step - loss: 0.3858 - acc: 0.8071 - val_loss: 0.1293 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99943\n",
      "Epoch 19/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.3854 - acc: 0.8075 - val_loss: 0.1657 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99943\n",
      "Epoch 20/25\n",
      "140272/140272 [==============================] - 21s 149us/step - loss: 0.3846 - acc: 0.8093 - val_loss: 0.1241 - val_acc: 0.9976\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99943\n",
      "Epoch 21/25\n",
      "140272/140272 [==============================] - 22s 154us/step - loss: 0.3834 - acc: 0.8108 - val_loss: 0.1241 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99943\n",
      "Epoch 22/25\n",
      "140272/140272 [==============================] - 22s 154us/step - loss: 0.3822 - acc: 0.8112 - val_loss: 0.1165 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99943\n",
      "Epoch 23/25\n",
      "140272/140272 [==============================] - 21s 148us/step - loss: 0.3818 - acc: 0.8120 - val_loss: 0.1129 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99943\n",
      "Epoch 24/25\n",
      "140272/140272 [==============================] - 22s 159us/step - loss: 0.3819 - acc: 0.8127 - val_loss: 0.1489 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99943\n",
      "Epoch 25/25\n",
      "140272/140272 [==============================] - 22s 159us/step - loss: 0.3814 - acc: 0.8137 - val_loss: 0.1312 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99943\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "traindata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=1,skipfooter=35069,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "testdata=pd.read_csv('UNSW_NB15_training_set.csv',skiprows=140273,names=['id','dur','proto','service','state','spkts','dpkts','sbytes','dbytes','rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat','smean','dmean','trans_depth','response_body_len','ct_srv_src','ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_src_ltm','ct_srv_dst','is_sm_ips_ports','attack_cat','label'])\n",
    "\n",
    "\n",
    "for column in traindata.columns:\n",
    "    if traindata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        traindata[column] = le.fit_transform(traindata[column])\n",
    "\n",
    "for column in testdata.columns:\n",
    "    if testdata[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        testdata[column] = le.fit_transform(testdata[column])\n",
    "\n",
    "X = traindata.iloc[:,1:44]\n",
    "Y = traindata.iloc[:,44]\n",
    "C = testdata.iloc[:,44]\n",
    "T = testdata.iloc[:,1:44]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32,input_dim=43, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=True))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(32, return_sequences=False))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/rnn3/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('training_set_iranalysis1.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=25, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/rnn3/rnn3_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
